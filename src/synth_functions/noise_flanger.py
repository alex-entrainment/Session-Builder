
import numpy as np
import numba
import soundfile as sf
from scipy import signal
import time
import tempfile
import argparse
import os
from typing import Dict


def _safe_close_memmap(mm):
    """Flush and close a memmap object if provided."""
    if isinstance(mm, np.memmap):
        try:
            mm.flush()
        except Exception:
            pass
        try:
            mm._mmap.close()
        except Exception:
            pass


def _safe_remove(path):
    """Remove a temporary file, ignoring missing file errors."""
    if not path:
        return
    try:
        os.remove(path)
    except FileNotFoundError:
        pass
    except PermissionError:
        pass

# If these exist in your project; harmless if unused here.
from .common import (
    calculate_transition_alpha,
    blue_noise,
    purple_noise,
    green_noise,
    deep_brown_noise,
)
from .spatial_ambi2d import spatialize_binaural_mid_only, generate_azimuth_trajectory

# --- Parameters ---
DEFAULT_SAMPLE_RATE = 44100  # Hz
DEFAULT_LFO_FREQ = 1.0 / 12.0  # Hz, for 12-second period


def _time_varying_notch_coefficients(freq_series, q_series, sample_rate):
    """Compute per-sample normalized biquad coefficients for a swept notch."""
    freq_series = np.clip(np.asarray(freq_series, dtype=np.float64), 1.0, sample_rate * 0.49 - 1e-6)
    q_series = np.maximum(np.asarray(q_series, dtype=np.float64), 1e-6)
    w0 = 2.0 * np.pi * freq_series / sample_rate
    cos_w0 = np.cos(w0)
    sin_w0 = np.sin(w0)
    alpha = sin_w0 / (2.0 * q_series)

    a0 = 1.0 + alpha
    inv_a0 = 1.0 / a0
    b0 = inv_a0
    b1 = (-2.0 * cos_w0) * inv_a0
    b2 = inv_a0
    a1 = (-2.0 * cos_w0) * inv_a0
    a2 = (1.0 - alpha) * inv_a0
    return b0, b1, b2, a1, a2


@numba.njit(cache=False)
def _time_varying_biquad(block, b0, b1, b2, a1, a2, state, casc_counts):
    """Apply time-varying notch coefficients with persistent state per cascade."""
    n = block.shape[0]
    max_stages = state.shape[0]
    for i in range(n):
        sample = block[i]
        casc = casc_counts[i]
        if casc < 1:
            casc = 1
        elif casc > max_stages:
            casc = max_stages
        for s in range(casc):
            z1 = state[s, 0]
            z2 = state[s, 1]
            y = sample * b0[i] + z1
            z1 = sample * b1[i] - y * a1[i] + z2
            z2 = sample * b2[i] - y * a2[i]
            state[s, 0] = z1
            state[s, 1] = z2
            sample = y
        block[i] = sample
    return block


def _pad_series(series, start_idx, block_size, fallback_value=0.0):
    """Slice `series` for a block and pad with the last available value."""
    segment = series[start_idx : start_idx + block_size]
    if segment.shape[0] < block_size:
        if segment.shape[0] == 0:
            pad_val = fallback_value
        else:
            pad_val = float(segment[-1])
        segment = np.pad(segment, (0, block_size - segment.shape[0]), constant_values=pad_val)
    return np.asarray(segment, dtype=np.float64)


def _filter_block_with_swept_notch(block, freq_series, q_series, casc_counts, state, sample_rate):
    """Filter a block in-place with per-sample notch coefficients and persistent state."""
    b0, b1, b2, a1, a2 = _time_varying_notch_coefficients(freq_series, q_series, sample_rate)
    casc_counts = np.asarray(casc_counts, dtype=np.int64)
    casc_counts = np.clip(casc_counts, 1, state.shape[0])
    return _time_varying_biquad(block, b0, b1, b2, a1, a2, state, casc_counts)


# =========================================================
# Loudness / limiting / dynamics helpers (POST PROCESSING)
# =========================================================
def _db_to_lin(db: float) -> float:
    return 10.0 ** (db / 20.0)


def _rms(x: np.ndarray) -> float:
    return float(np.sqrt(np.mean(np.float64(x) * np.float64(x))) + 1e-20)


def _normalize_rms(x: np.ndarray, target_dbfs: float = -18.0) -> np.ndarray:
    """Scale entire signal to a target RMS (dBFS)."""
    cur = _rms(x)
    tgt = _db_to_lin(target_dbfs)
    if cur <= 0.0:
        return x
    return (x * (tgt / cur)).astype(np.float32, copy=False)


def _soft_clip_tanh(x: np.ndarray, drive_db: float = 0.0, ceiling_db: float = -1.0) -> np.ndarray:
    """Gentle tanh soft clip. drive_db > 0 adds a bit of saturation; ceiling sets final peak."""
    if abs(drive_db) <= 1e-9 and ceiling_db >= 0.0:
        return x
    drive = _db_to_lin(drive_db)
    ceil = _db_to_lin(ceiling_db)
    y = np.tanh(x * drive) / np.tanh(1.0)  # unity at 1.0 in
    peak = float(np.max(np.abs(y))) + 1e-12
    y = y * min(ceil / peak, 1.0)
    return y.astype(np.float32, copy=False)


def true_peak_limiter(
    x: np.ndarray,
    fs: int,
    ceiling_db: float = -1.0,
    lookahead_ms: float = 2.0,
    release_ms: float = 60.0,
    oversample: int = 4,
) -> np.ndarray:
    """
    Look-ahead true-peak limiter:
      - oversamples to catch inter-sample peaks,
      - schedules minimum gain over lookahead,
      - one-pole release toward unity,
      - decimates back and trims to ceiling.
    """
    from collections import deque

    ceil = _db_to_lin(ceiling_db)
    oversample = max(1, int(oversample))

    # Oversample
    if oversample > 1:
        x_os = signal.resample_poly(x, oversample, 1)
        fs_os = fs * oversample
    else:
        x_os = x.astype(np.float32, copy=False)
        fs_os = fs

    N = x_os.size
    eps = 1e-12
    look = max(1, int(lookahead_ms * 1e-3 * fs_os))
    rel_a = np.exp(-1.0 / max(1.0, (release_ms * 1e-3) * fs_os))

    desired = np.minimum(1.0, ceil / (np.abs(x_os) + eps)).astype(np.float32)

    # Sliding min over next 'look' samples -> gmin[i] = min(desired[i:i+look+1])
    gmin = np.ones_like(desired)
    q = deque()
    for i in range(N + look):
        if i < N:
            val = desired[i]
            while q and q[-1][1] >= val:
                q.pop()
            q.append((i, val))
        while q and q[0][0] < i - look:
            q.popleft()
        if i - look >= 0:
            gmin[i - look] = q[0][1] if q else 1.0

    # Release smoothing (toward 1.0, never above gmin)
    g = np.empty_like(gmin)
    gp = 1.0
    for i in range(N):
        gp = min(gmin[i], 1.0 - (1.0 - gp) * rel_a)
        g[i] = gp

    y_os = (x_os * g).astype(np.float32, copy=False)

    # Decimate back
    if oversample > 1:
        y = signal.resample_poly(y_os, 1, oversample)
        peak = float(np.max(np.abs(y))) + eps
        if peak > ceil:
            y = y * (ceil / peak)
        return y.astype(np.float32, copy=False)
    else:
        return y_os


# ---------- NEW: crest-factor cap + loudness leveler ----------
def _moving_rms(x: np.ndarray, win: int) -> np.ndarray:
    """Centered moving RMS with window `win` samples."""
    eps = 1e-12
    if win <= 1:
        return np.sqrt(np.float64(x) * np.float64(x) + eps).astype(np.float32)
    k = np.ones(win, dtype=np.float64) / float(win)
    p = np.convolve(np.float64(x) ** 2, k, mode="same")
    return np.sqrt(p + eps).astype(np.float32)


def _sliding_abs_max(x: np.ndarray, win: int) -> np.ndarray:
    """Sliding window absolute-peak with O(N) deque; window length `win` samples."""
    from collections import deque

    N = x.size
    win = max(1, int(win))
    out = np.empty(N, dtype=np.float32)
    q = deque()  # holds (index, value) with decreasing value
    ax = np.abs(x).astype(np.float32, copy=False)

    for i in range(N + win - 1):
        if i < N:
            v = float(ax[i])
            while q and q[-1][1] <= v:
                q.pop()
            q.append((i, v))
        # Drop elements out of window [i - win + 1, i]
        left = i - win + 1
        while q and q[0][0] < left:
            q.popleft()
        if left >= 0:
            out[left] = q[0][1] if q else 0.0

    # For the first win-1 samples (before the first valid center), repeat the first value.
    if win > 1:
        out[: win - 1] = out[win - 1]
    return out


def crest_factor_leveler(
    x: np.ndarray,
    fs: int,
    cap_db: float = 12.0,
    peak_window_ms: float = 10.0,
    rms_window_ms: float = 200.0,
    attack_ms: float = 3.0,
    release_ms: float = 80.0,
    hp_weight_hz: float = 60.0,
) -> np.ndarray:
    """
    Reduce gain only when local crest factor (peak_dB - rms_dB) exceeds `cap_db`.
    - peak envelope: sliding absolute max over `peak_window_ms`
    - rms envelope: centered moving RMS over `rms_window_ms`
    - optional HP weighting so sub-bass doesn't dominate RMS
    """
    x = x.astype(np.float32, copy=False)
    eps = 1e-12

    # Perceptual-ish RMS weighting (high-pass)
    if hp_weight_hz and hp_weight_hz > 0:
        b, a = signal.butter(2, hp_weight_hz, btype="high", fs=fs)
        x_rms_src = signal.lfilter(b, a, x).astype(np.float32)
    else:
        x_rms_src = x

    n_peak = max(1, int(peak_window_ms * 1e-3 * fs))
    n_rms = max(1, int(rms_window_ms * 1e-3 * fs))

    peak_env = _sliding_abs_max(x, n_peak) + eps
    rms_env = _moving_rms(x_rms_src, n_rms) + eps

    peak_db = 20.0 * np.log10(peak_env)
    rms_db = 20.0 * np.log10(rms_env)

    crest_db = peak_db - rms_db
    excess_db = np.maximum(0.0, crest_db - float(cap_db)).astype(np.float32)

    # Fast-attack / slow-release smoothing in dB domain
    a_att = np.exp(-1.0 / max(1.0, (attack_ms * 1e-3) * fs))
    a_rel = np.exp(-1.0 / max(1.0, (release_ms * 1e-3) * fs))
    red_db = np.empty_like(excess_db)
    s = float(excess_db[0])
    for i in range(excess_db.size):
        e = float(excess_db[i])
        s = a_att * s + (1.0 - a_att) * e if e > s else a_rel * s + (1.0 - a_rel) * e
        red_db[i] = s

    g = 10.0 ** (-red_db / 20.0)
    return (x * g).astype(np.float32, copy=False)


def loudness_leveler(
    x: np.ndarray,
    fs: int,
    target_db: float = -12.0,
    window_ms: float = 300.0,
    attack_ms: float = 40.0,
    release_ms: float = 200.0,
    max_up_db: float = 6.0,
    max_down_db: float = 12.0,
    hp_weight_hz: float = 60.0,
) -> np.ndarray:
    """
    Time-varying gain to hold short-term loudness near `target_db`.
    Uses moving RMS (HP-weighted) with attack/release smoothing.
    """
    x = x.astype(np.float32, copy=False)
    eps = 1e-12

    if hp_weight_hz and hp_weight_hz > 0:
        b, a = signal.butter(2, hp_weight_hz, btype="high", fs=fs)
        x_w = signal.lfilter(b, a, x).astype(np.float32)
    else:
        x_w = x

    n = max(1, int(window_ms * 1e-3 * fs))
    rms = _moving_rms(x_w, n) + eps
    rms_db = 20.0 * np.log10(rms)

    want_db = float(target_db)
    delta_db = np.clip(want_db - rms_db, -abs(max_down_db), abs(max_up_db)).astype(np.float32)

    a_att = np.exp(-1.0 / max(1.0, (attack_ms * 1e-3) * fs))
    a_rel = np.exp(-1.0 / max(1.0, (release_ms * 1e-3) * fs))
    gdb = np.empty_like(delta_db)
    s = float(delta_db[0])
    for i in range(delta_db.size):
        d = float(delta_db[i])
        s = a_att * s + (1.0 - a_att) * d if d < s else a_rel * s + (1.0 - a_rel) * d
        gdb[i] = s

    g = 10.0 ** (gdb / 20.0)
    return (x * g).astype(np.float32, copy=False)


# =======================================
# Utility for memory-mapped RMS (notches)
# =======================================
def _compute_rms_memmap(arr, chunk_size=1_000_000):
    """Compute RMS of a potentially memory-mapped array in chunks."""
    n = len(arr)
    if n == 0:
        return 0.0
    sq_sum = 0.0
    for i in range(0, n, chunk_size):
        chunk = arr[i : i + chunk_size]
        sq_sum += np.sum(chunk.astype(np.float64) ** 2)
    return np.sqrt(sq_sum / n)


# =========================
# Noise generators
# =========================
@numba.jit(nopython=True)
def generate_pink_noise_samples(n_samples):
    """Pink noise via Paul Kellett's filter (Numba)."""
    white = np.random.randn(n_samples).astype(np.float32)
    pink = np.empty_like(white)

    # State variables
    b0, b1, b2, b3, b4, b5 = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0

    for i in range(n_samples):
        w = white[i]
        b0 = 0.99886 * b0 + w * 0.0555179
        b1 = 0.99332 * b1 + w * 0.0750759
        b2 = 0.96900 * b2 + w * 0.1538520
        b3 = 0.86650 * b3 + w * 0.3104856
        b4 = 0.55000 * b4 + w * 0.5329522
        b5 = -0.7616 * b5 - w * 0.0168980
        pink_val = b0 + b1 + b2 + b3 + b4 + b5
        pink[i] = pink_val * 0.11
    return pink


@numba.jit(nopython=True)
def generate_brown_noise_samples(n_samples):
    """Brown (red) noise via integrated white."""
    white = np.random.randn(n_samples).astype(np.float32)
    brown = np.cumsum(white)
    max_abs = np.max(np.abs(brown)) + 1e-8
    return (brown / max_abs).astype(np.float32)


def _finalize_noise_length(noise: np.ndarray, target: int) -> np.ndarray:
    target = int(target)
    if noise.size < target:
        noise = np.pad(noise, (0, target - noise.size))
    elif noise.size > target:
        noise = noise[:target]
    return noise.astype(np.float32, copy=False)


def _generate_colored_noise_from_presets(
    n_samples: int, sample_rate: int, noise_type: object
):
    """Return colored noise from presets when available.

    This allows custom colours defined in :mod:`src.utils.colored_noise` to be
    used seamlessly by the main noise generator dialog. When no matching
    preset is found (or dependencies are unavailable), ``None`` is returned so
    the caller can fall back to built-in options.
    """

    try:
        from src.utils.colored_noise import (
            DEFAULT_COLOR_PRESETS,
            ColoredNoiseGenerator,
            apply_preset_to_generator,
            load_custom_color_presets,
        )
    except Exception:
        return None

    if isinstance(noise_type, dict):
        noise_name = noise_type.get("name")
    else:
        noise_name = noise_type

    key = str(noise_name or "").strip().lower()
    if not key:
        return None

    presets = {name.lower(): params for name, params in DEFAULT_COLOR_PRESETS.items()}
    for name, preset in load_custom_color_presets().items():
        presets[name.lower()] = preset

    preset = presets.get(key)
    if preset is None:
        return None

    generator = apply_preset_to_generator(
        ColoredNoiseGenerator(
            sample_rate=sample_rate,
            duration=float(n_samples) / float(sample_rate),
        ),
        preset,
    )
    noise = generator.generate()

    return _finalize_noise_length(noise, n_samples)


def _generate_colored_noise_from_parameters(
    n_samples: int, sample_rate: int, color_params: Dict[str, object]
):
    """Return colored noise using explicit parameter dictionaries when possible."""

    try:
        from src.utils.colored_noise import (
            PRESET_FIELDS,
            ColoredNoiseGenerator,
            apply_preset_to_generator,
        )
    except Exception:
        return None

    if not isinstance(color_params, dict):
        return None

    preset = {k: v for k, v in color_params.items() if k in PRESET_FIELDS}
    if not preset:
        name = color_params.get("name")
        if isinstance(name, str):
            return _generate_colored_noise_from_presets(n_samples, sample_rate, name)
        return None

    generator = apply_preset_to_generator(
        ColoredNoiseGenerator(
            sample_rate=sample_rate,
            duration=float(n_samples) / float(sample_rate),
        ),
        preset,
    )
    return _finalize_noise_length(generator.generate(), n_samples)


def generate_noise_samples(n_samples, noise_spec, sample_rate=DEFAULT_SAMPLE_RATE):
    if isinstance(noise_spec, dict):
        colored = _generate_colored_noise_from_parameters(n_samples, sample_rate, noise_spec)
        if colored is not None:
            return colored
        nt = str(noise_spec.get("name", "")).lower()
    else:
        nt = str(noise_spec).lower()

    if nt == "pink":
        return generate_pink_noise_samples(n_samples)
    if nt in ("brown", "red"):
        return generate_brown_noise_samples(n_samples)
    if nt == "deep brown":
        return deep_brown_noise(n_samples).astype(np.float32)
    if nt == "blue":
        return blue_noise(n_samples).astype(np.float32)
    if nt == "purple":
        return purple_noise(n_samples).astype(np.float32)
    if nt == "green":
        return green_noise(n_samples, fs=sample_rate).astype(np.float32)
    colored = _generate_colored_noise_from_presets(n_samples, sample_rate, nt)
    if colored is not None:
        return colored
    return np.random.randn(n_samples).astype(np.float32)


# =========================
# Helper utilities for synth voice usage
# =========================
def _safe_float(value, default):
    try:
        return float(value)
    except (TypeError, ValueError):
        return float(default)


def _safe_int(value, default):
    try:
        return int(round(float(value)))
    except (TypeError, ValueError):
        return int(default)


def _prepare_static_notches(static_notches, limit=10):
    """Parse a static notch specification into ``(freq, q, cascade)`` tuples."""
    if not static_notches:
        return []

    parsed = []
    for entry in static_notches:
        if len(parsed) >= int(limit):
            break

        freq = 1000.0
        q_val = 25.0
        casc = 1

        if isinstance(entry, dict):
            freq = _safe_float(
                entry.get("freq", entry.get("frequency", entry.get("hz", 1000.0))),
                1000.0,
            )
            q_val = _safe_float(entry.get("q", entry.get("quality", 25.0)), 25.0)
            casc = _safe_int(entry.get("cascade", entry.get("count", 1)), 1)
        elif isinstance(entry, (list, tuple)):
            items = list(entry)
            if items:
                freq = _safe_float(items[0], 1000.0)
            if len(items) > 1:
                q_val = _safe_float(items[1], 25.0)
            if len(items) > 2:
                casc = _safe_int(items[2], 1)
        else:
            continue

        freq = max(1.0, float(freq))
        q_val = max(0.1, float(q_val))
        casc = max(1, int(casc))
        parsed.append((freq, q_val, casc))

    return parsed


def _apply_static_notches(stereo_output, sample_rate, static_notches):
    """Apply non-modulated notch filters to ``stereo_output`` in-place."""
    parsed = _prepare_static_notches(static_notches)
    if not parsed:
        return stereo_output

    left = stereo_output[:, 0].astype(np.float64, copy=True)
    right = stereo_output[:, 1].astype(np.float64, copy=True)

    nyquist = sample_rate * 0.49
    for freq, q_val, casc in parsed:
        if freq <= 0.0 or freq >= nyquist:
            continue

        try:
            b, a = signal.iirnotch(freq, q_val, sample_rate)
        except ValueError:
            continue

        for _ in range(casc):
            left = signal.filtfilt(b, a, left)
            right = signal.filtfilt(b, a, right)

    stereo_output[:, 0] = left.astype(np.float32)
    stereo_output[:, 1] = right.astype(np.float32)
    return stereo_output


def _prepare_static_sweeps(sweeps):
    """Convert a ``sweeps`` specification into arrays for the notch helpers."""
    if sweeps is None:
        return [(1000.0, 10000.0)], [25.0], [10]
    if not sweeps:
        return [], [], []

    filter_sweeps = []
    q_vals = []
    casc_vals = []

    for entry in sweeps:
        if isinstance(entry, dict):
            min_f = _safe_float(
                entry.get("min", entry.get("start_min", entry.get("startMin", 1000.0))),
                1000.0,
            )
            max_f = _safe_float(
                entry.get("max", entry.get("start_max", entry.get("startMax", 10000.0))),
                10000.0,
            )
            q_val = _safe_float(entry.get("q", entry.get("start_q", 25.0)), 25.0)
            casc = _safe_int(entry.get("cascade", entry.get("start_casc", 10)), 10)
        elif isinstance(entry, (list, tuple)):
            min_f = _safe_float(entry[0] if len(entry) > 0 else 1000.0, 1000.0)
            max_f = _safe_float(entry[1] if len(entry) > 1 else 10000.0, 10000.0)
            q_val = _safe_float(entry[2] if len(entry) > 2 else 25.0, 25.0)
            casc = _safe_int(entry[3] if len(entry) > 3 else 10, 10)
        else:
            min_f, max_f, q_val, casc = 1000.0, 10000.0, 25.0, 10

        if min_f > max_f:
            min_f, max_f = max_f, min_f

        filter_sweeps.append((float(min_f), float(max_f)))
        q_vals.append(float(q_val))
        casc_vals.append(int(max(1, casc)))

    return filter_sweeps, q_vals, casc_vals


def _prepare_transition_sweeps(sweeps):
    if sweeps is None:
        defaults = [(1000.0, 10000.0)]
        return defaults, defaults, [25.0], [25.0], [10], [10]
    if not sweeps:
        return [], [], [], [], [], []

    start_sweeps = []
    end_sweeps = []
    start_q_vals = []
    end_q_vals = []
    start_casc = []
    end_casc = []

    for entry in sweeps:
        if isinstance(entry, dict):
            start_min = _safe_float(
                entry.get("start_min", entry.get("min", entry.get("startMin", 1000.0))),
                1000.0,
            )
            start_max = _safe_float(
                entry.get("start_max", entry.get("max", entry.get("startMax", 10000.0))),
                10000.0,
            )
            end_min = _safe_float(
                entry.get("end_min", entry.get("endMin", entry.get("max", start_min))),
                start_min,
            )
            end_max = _safe_float(
                entry.get("end_max", entry.get("endMax", entry.get("max", start_max))),
                start_max,
            )
            start_q = _safe_float(entry.get("start_q", entry.get("q", 25.0)), 25.0)
            end_q = _safe_float(entry.get("end_q", entry.get("q", start_q)), start_q)
            start_c = _safe_int(entry.get("start_casc", entry.get("cascade", 10)), 10)
            end_c = _safe_int(entry.get("end_casc", entry.get("cascade", start_c)), start_c)
        elif isinstance(entry, (list, tuple)):
            vals = list(entry)
            start_min = _safe_float(vals[0] if len(vals) > 0 else 1000.0, 1000.0)
            start_max = _safe_float(vals[1] if len(vals) > 1 else 10000.0, 10000.0)
            end_min = _safe_float(vals[2] if len(vals) > 2 else start_min, start_min)
            end_max = _safe_float(vals[3] if len(vals) > 3 else start_max, start_max)
            start_q = _safe_float(vals[4] if len(vals) > 4 else 25.0, 25.0)
            end_q = _safe_float(vals[5] if len(vals) > 5 else start_q, start_q)
            start_c = _safe_int(vals[6] if len(vals) > 6 else 10, 10)
            end_c = _safe_int(vals[7] if len(vals) > 7 else start_c, start_c)
        else:
            start_min, start_max = 1000.0, 10000.0
            end_min, end_max = start_min, start_max
            start_q = end_q = 25.0
            start_c = end_c = 10

        if start_min > start_max:
            start_min, start_max = start_max, start_min
        if end_min > end_max:
            end_min, end_max = end_max, end_min

        start_sweeps.append((float(start_min), float(start_max)))
        end_sweeps.append((float(end_min), float(end_max)))
        start_q_vals.append(float(start_q))
        end_q_vals.append(float(end_q))
        start_casc.append(int(max(1, start_c)))
        end_casc.append(int(max(1, end_c)))

    return start_sweeps, end_sweeps, start_q_vals, end_q_vals, start_casc, end_casc


def _build_noise_envelope(num_samples, sample_rate, fade_in=0.0, fade_out=0.0, amp_envelope=None):
    env = np.ones(num_samples, dtype=np.float32)
    if num_samples == 0:
        return env

    fade_in = max(0.0, _safe_float(fade_in, 0.0))
    fade_out = max(0.0, _safe_float(fade_out, 0.0))

    if fade_in > 0.0:
        n = min(int(round(fade_in * sample_rate)), num_samples)
        if n > 0:
            env[:n] *= np.linspace(0.0, 1.0, n, dtype=np.float32)

    if fade_out > 0.0:
        n = min(int(round(fade_out * sample_rate)), num_samples)
        if n > 0:
            env[-n:] *= np.linspace(1.0, 0.0, n, dtype=np.float32)

    if amp_envelope:
        times = []
        amps = []
        for point in amp_envelope:
            if isinstance(point, dict):
                t = _safe_float(point.get("time", point.get("t", point.get("x", 0.0))), 0.0)
                a = _safe_float(point.get("amp", point.get("value", point.get("y", 1.0))), 1.0)
            elif isinstance(point, (list, tuple)) and len(point) >= 2:
                t = _safe_float(point[0], 0.0)
                a = _safe_float(point[1], 1.0)
            else:
                continue
            times.append(max(0.0, t))
            amps.append(a)

        if amps:
            order = np.argsort(times)
            times_arr = np.array(times, dtype=np.float64)[order]
            amps_arr = np.array(amps, dtype=np.float32)[order]

            if times_arr.size == 1:
                env *= amps_arr[0]
            else:
                sample_positions = np.arange(num_samples, dtype=np.float64)
                env *= np.interp(
                    sample_positions,
                    times_arr * sample_rate,
                    amps_arr,
                    left=amps_arr[0],
                    right=amps_arr[-1],
                ).astype(np.float32)

    return env


def _resolve_channel_amp(base_start, base_end, start_val=None, end_val=None):
    start = _safe_float(start_val if start_val is not None else base_start, base_start)
    end = _safe_float(end_val if end_val is not None else base_end, base_end)
    return float(start), float(end)


# =========================
# Simple flanger (legacy)
# =========================
def triangle_wave_varying(freq_array, t, sample_rate=44100):
    """Generate a triangle wave with a time-varying frequency."""
    freq_array = np.maximum(np.asarray(freq_array, dtype=float), 1e-9)
    t = np.asarray(t, dtype=float)
    if len(t) <= 1:
        return np.zeros_like(t)
    dt = np.diff(t, prepend=t[0])
    phase = 2 * np.pi * np.cumsum(freq_array * dt)
    return signal.sawtooth(phase, width=0.5)


def apply_flanger(
    input_signal,
    sample_rate,
    lfo_freq=0.1,
    max_delay_ms=5.0,
    mix=0.5,
    direction="up",
    lfo_waveform="sine",
    feedback=0.0,
    initial_offset=0.0,
):
    """Apply a flanging effect to ``input_signal``."""
    n = len(input_signal)
    t = (np.arange(n) / sample_rate) + initial_offset
    if lfo_waveform.lower() == "triangle":
        lfo = signal.sawtooth(2 * np.pi * lfo_freq * t, width=0.5)
    else:
        lfo = np.sin(2 * np.pi * lfo_freq * t)
    if direction == "down":
        lfo = -lfo

    if n > 5:
        lfo = signal.savgol_filter(lfo, 5, 2, mode="interp")

    max_delay = max_delay_ms / 1000.0 * sample_rate
    delay = (lfo + 1.0) * 0.5 * max_delay

    pad = int(np.ceil(max_delay)) + 2
    buffer = np.concatenate((np.zeros(pad, dtype=np.float32), input_signal.astype(np.float32)))
    output = np.zeros(n, dtype=np.float32)

    for i in range(n):
        read_pos = pad + i - delay[i]
        i0 = int(np.floor(read_pos))
        frac = read_pos - i0
        y0 = buffer[i0]
        y1 = buffer[i0 + 1]
        delayed = y0 + frac * (y1 - y0)
        buffer[pad + i] += delayed * feedback
        output[i] = input_signal[i] * (1 - mix) + delayed * mix

    return output


def generate_flanged_noise(
    duration_seconds,
    sample_rate=DEFAULT_SAMPLE_RATE,
    noise_type="pink",
    lfo_freq=0.1,
    max_delay_ms=5.0,
    mix=0.5,
    direction="up",
    lfo_waveform="sine",
    initial_offset=0.0,
):
    """Generate noise and apply a flanger."""
    num_samples = int(duration_seconds * sample_rate)
    noise = generate_noise_samples(num_samples, noise_type, sample_rate)
    return apply_flanger(
        noise,
        sample_rate,
        lfo_freq=lfo_freq,
        max_delay_ms=max_delay_ms,
        mix=mix,
        direction=direction,
        lfo_waveform=lfo_waveform,
        initial_offset=initial_offset,
    )


# ==========================================
# Swept-notch machinery (with transition)
# ==========================================
def _apply_deep_swept_notches_varying(
    input_signal,
    sample_rate,
    lfo_array,
    min_freq_arrays,
    max_freq_arrays,
    notch_q_arrays,
    cascade_count_arrays,
    use_memmap=True,
):
    """Apply swept notch filters where parameters vary over time."""
    n_samples = len(input_signal)

    temp_files = []
    memmaps = []
    if use_memmap:
        tmp_output = tempfile.NamedTemporaryFile(delete=False)
        tmp_output_name = tmp_output.name
        tmp_output.close()
        temp_files.append(tmp_output_name)
        output = np.memmap(tmp_output_name, dtype=np.float32, mode="w+", shape=n_samples)
        memmaps.append(output)
        output[:] = input_signal[:]
    else:
        output = input_signal.copy()

    block_size = 4096
    hop_size = block_size // 2
    window = np.hanning(block_size)

    if use_memmap:
        tmp_out_acc = tempfile.NamedTemporaryFile(delete=False)
        tmp_win_acc = tempfile.NamedTemporaryFile(delete=False)
        out_acc_name = tmp_out_acc.name
        win_acc_name = tmp_win_acc.name
        tmp_out_acc.close()
        tmp_win_acc.close()
        temp_files.extend([out_acc_name, win_acc_name])
        output_accumulator = np.memmap(out_acc_name, dtype=np.float32, mode="w+", shape=n_samples + block_size)
        window_accumulator = np.memmap(win_acc_name, dtype=np.float32, mode="w+", shape=n_samples + block_size)
        memmaps.extend([output_accumulator, window_accumulator])
    else:
        output_accumulator = np.zeros(n_samples + block_size, dtype=np.float32)
        window_accumulator = np.zeros(n_samples + block_size, dtype=np.float32)

    num_blocks = (n_samples + hop_size - 1) // hop_size
    num_sweeps = len(min_freq_arrays)

    # Initialize persistent filter states for each sweep.
    # For varying mode, we need to track max cascade count per sweep.
    # Structure: filter_states[sweep_idx][cascade_idx] = zi
    max_cascades = []
    for i in range(num_sweeps):
        max_casc = int(np.max(cascade_count_arrays[i]))
        max_cascades.append(max(1, max_casc))
    filter_states = [[None] * max_cascades[i] for i in range(num_sweeps)]

    for block_idx in range(num_blocks):
        start_idx = block_idx * hop_size
        end_idx = min(start_idx + block_size, n_samples)
        actual_block_size = end_idx - start_idx
        if actual_block_size < 100:
            continue

        # Copy block WITHOUT windowing - filter sees continuous signal
        block = np.zeros(block_size)
        block[:actual_block_size] = output[start_idx:end_idx]

        # Filter the unwindowed block (filter-before-window architecture)
        filtered_block = block.copy()

        center_idx = start_idx + actual_block_size // 2

        for i in range(num_sweeps):
            min_f = min_freq_arrays[i][center_idx]
            max_f = max_freq_arrays[i][center_idx]
            center_freq = (min_f + max_f) / 2.0
            freq_range = (max_f - min_f) / 2.0
            notch_freq = center_freq + freq_range * lfo_array[center_idx]

            if notch_freq >= sample_rate * 0.49 or notch_freq <= 0:
                continue

            q_val = float(notch_q_arrays[i][center_idx])
            casc = int(round(cascade_count_arrays[i][center_idx]))
            casc = max(1, min(casc, max_cascades[i]))
            for casc_idx in range(casc):
                try:
                    b, a = signal.iirnotch(notch_freq, q_val, sample_rate)
                    # Use persistent filter state to avoid block-edge transients
                    zi = filter_states[i][casc_idx]
                    if zi is None:
                        zi = signal.lfilter_zi(b, a) * filtered_block[0]
                    filtered_block, zi = signal.lfilter(b, a, filtered_block, zi=zi)
                    filter_states[i][casc_idx] = zi
                except ValueError:
                    continue

        # Apply window AFTER filtering to ensure proper OLA reconstruction
        windowed_filtered = filtered_block * window

        output_accumulator[start_idx : start_idx + block_size] += windowed_filtered
        window_accumulator[start_idx : start_idx + block_size] += window

    valid_idx = window_accumulator > 1e-8
    output_accumulator[valid_idx] /= window_accumulator[valid_idx]

    if use_memmap:
        result = np.array(output_accumulator[:n_samples], copy=True)
    else:
        result = output_accumulator[:n_samples]

    for mm in memmaps:
        _safe_close_memmap(mm)
    for path in temp_files:
        _safe_remove(path)

    return result


def _apply_deep_swept_notches_single_phase(
    input_signal,
    sample_rate,
    lfo_freq,
    filter_sweeps,
    notch_q=30,
    cascade_count=10,
    phase_offset=90,
    lfo_waveform="sine",
    use_memmap=True,
    initial_offset=0.0,
):
    """Apply one or more deep swept notch filters for a single LFO phase."""
    n_samples = len(input_signal)

    temp_files = []
    memmaps = []
    if use_memmap:
        tmp_output = tempfile.NamedTemporaryFile(delete=False)
        tmp_output_name = tmp_output.name
        tmp_output.close()
        temp_files.append(tmp_output_name)
        output = np.memmap(tmp_output_name, dtype=np.float32, mode="w+", shape=n_samples)
        memmaps.append(output)
        output[:] = input_signal[:]
    else:
        output = input_signal.copy()

    t = (np.arange(n_samples) / sample_rate) + initial_offset

    # --- LFO Generation ---
    if lfo_waveform.lower() == "triangle":
        lfo = signal.sawtooth(2 * np.pi * lfo_freq * t + phase_offset, width=0.5)
    elif lfo_waveform.lower() == "sine":
        lfo = np.cos(2 * np.pi * lfo_freq * t + phase_offset)
    else:
        raise ValueError(f"Unsupported LFO waveform: {lfo_waveform}. Choose 'sine' or 'triangle'.")

    # --- Generate Frequency Sweeps for each filter ---
    base_freq_sweeps = []
    for min_freq, max_freq in filter_sweeps:
        center_freq = (min_freq + max_freq) / 2
        freq_range = (max_freq - min_freq) / 2
        base_freq_sweeps.append(center_freq + freq_range * lfo)

    # Normalize parameter shapes
    if isinstance(notch_q, (int, float)):
        notch_qs = [float(notch_q)] * len(filter_sweeps)
    else:
        notch_qs = list(notch_q)
    if isinstance(cascade_count, int):
        cascade_counts = [int(cascade_count)] * len(filter_sweeps)
    else:
        cascade_counts = list(cascade_count)
    if len(notch_qs) != len(filter_sweeps) or len(cascade_counts) != len(filter_sweeps):
        raise ValueError("Length of notch_q and cascade_count must match number of filter_sweeps")

    # Overlap-add processing
    block_size = 4096
    hop_size = block_size // 2
    window = np.hanning(block_size)

    if use_memmap:
        tmp_out_acc = tempfile.NamedTemporaryFile(delete=False)
        tmp_win_acc = tempfile.NamedTemporaryFile(delete=False)
        out_acc_name = tmp_out_acc.name
        win_acc_name = tmp_win_acc.name
        tmp_out_acc.close()
        tmp_win_acc.close()
        temp_files.extend([out_acc_name, win_acc_name])
        output_accumulator = np.memmap(out_acc_name, dtype=np.float32, mode="w+", shape=n_samples + block_size)
        window_accumulator = np.memmap(win_acc_name, dtype=np.float32, mode="w+", shape=n_samples + block_size)
        memmaps.extend([output_accumulator, window_accumulator])
    else:
        output_accumulator = np.zeros(n_samples + block_size, dtype=np.float32)
        window_accumulator = np.zeros(n_samples + block_size, dtype=np.float32)

    num_blocks = (n_samples + hop_size - 1) // hop_size

    # Initialize persistent filter states for each sweep and cascade stage.
    # This prevents transients at block boundaries by maintaining filter memory.
    # Structure: filter_states[sweep_idx][cascade_idx] = zi (filter state array)
    filter_states = []
    for sweep_idx in range(len(filter_sweeps)):
        cascades = cascade_counts[sweep_idx]
        sweep_states = [None] * cascades  # Will be initialized on first use
        filter_states.append(sweep_states)

    for block_idx in range(num_blocks):
        start_idx = block_idx * hop_size
        end_idx = min(start_idx + block_size, n_samples)
        actual_block_size = end_idx - start_idx
        if actual_block_size < 100:
            continue

        # Copy block WITHOUT windowing - filter sees continuous signal
        block = np.zeros(block_size)
        block[:actual_block_size] = output[start_idx:end_idx]

        # Filter the unwindowed block (filter-before-window architecture)
        filtered_block = block.copy()

        block_center_idx = start_idx + actual_block_size // 2

        for sweep_idx, sweep in enumerate(base_freq_sweeps):
            notch_freq = sweep[block_center_idx]
            if notch_freq >= sample_rate * 0.49 or notch_freq <= 0:
                continue
            q_val = notch_qs[sweep_idx]
            cascades = cascade_counts[sweep_idx]
            for casc_idx in range(cascades):
                try:
                    b, a = signal.iirnotch(notch_freq, q_val, sample_rate)
                    # Use persistent filter state to avoid block-edge transients
                    zi = filter_states[sweep_idx][casc_idx]
                    if zi is None:
                        # Initialize filter state on first use
                        zi = signal.lfilter_zi(b, a) * filtered_block[0]
                    filtered_block, zi = signal.lfilter(b, a, filtered_block, zi=zi)
                    filter_states[sweep_idx][casc_idx] = zi
                except ValueError:
                    continue

        # Apply window AFTER filtering to ensure proper OLA reconstruction
        # without IIR filter state discontinuities
        windowed_filtered = filtered_block * window

        output_accumulator[start_idx : start_idx + block_size] += windowed_filtered
        window_accumulator[start_idx : start_idx + block_size] += window

    valid_idx = window_accumulator > 1e-8
    output_accumulator[valid_idx] /= window_accumulator[valid_idx]

    if use_memmap:
        result = np.array(output_accumulator[:n_samples], copy=True)
    else:
        result = output_accumulator[:n_samples]

    for mm in memmaps:
        _safe_close_memmap(mm)
    for path in temp_files:
        _safe_remove(path)

    return result


def apply_deep_swept_notches(
    input_signal,
    sample_rate,
    lfo_freq,
    filter_sweeps,
    notch_q=30,
    cascade_count=10,
    phase_offset=0,
    extra_phase_offset=0.0,
    lfo_waveform="sine",
    use_memmap=False,
    initial_offset=0.0,
):
    """Wrapper for deep swept notch filters."""
    output = _apply_deep_swept_notches_single_phase(
        input_signal,
        sample_rate,
        lfo_freq,
        filter_sweeps,
        notch_q,
        cascade_count,
        phase_offset,
        lfo_waveform,
        use_memmap=use_memmap,
        initial_offset=initial_offset,
    )

    if extra_phase_offset:
        output = _apply_deep_swept_notches_single_phase(
            output,
            sample_rate,
            lfo_freq,
            filter_sweeps,
            notch_q,
            cascade_count,
            phase_offset + extra_phase_offset,
            lfo_waveform,
            use_memmap=use_memmap,
            initial_offset=initial_offset,
        )

    return output


def _generate_swept_notch_arrays(
    duration_seconds,
    sample_rate,
    lfo_freq,
    filter_sweeps,
    notch_q,
    cascade_count,
    lfo_phase_offset_deg,
    intra_phase_offset_deg,
    input_audio_path,
    noise_spec,
    lfo_waveform,
    memory_efficient,
    n_jobs,
    static_notches=None,
    initial_offset=0.0,
):
    """Internal helper to generate swept notch noise and return stereo array."""
    # Defensive normalization to handle malformed inputs from saved presets/UI.
    lfo_waveform = str(lfo_waveform or "sine").lower()

    if filter_sweeps is None:
        filter_sweeps = [(1000, 10000)]

    if isinstance(notch_q, (int, float)):
        notch_q = [float(notch_q)] * len(filter_sweeps)
    else:
        notch_q = list(notch_q)
    if isinstance(cascade_count, int):
        cascade_count = [int(cascade_count)] * len(filter_sweeps)
    else:
        cascade_count = list(cascade_count)

    # Force single-threaded execution to avoid Windows multiprocessing issues.
    n_jobs = 1
    if len(notch_q) != len(filter_sweeps) or len(cascade_count) != len(filter_sweeps):
        raise ValueError("Length of notch_q and cascade_count must match number of filter_sweeps")

    start_time = time.time()
    input_signal_memmap = None
    input_tmp_name = None
    try:
        if input_audio_path is None:
            num_samples = int(duration_seconds * sample_rate)
            if memory_efficient:
                tmp_input = tempfile.NamedTemporaryFile(delete=False)
                input_tmp_name = tmp_input.name
                tmp_input.close()
                input_signal = np.memmap(input_tmp_name, dtype=np.float32, mode="w+", shape=num_samples)
                input_signal[:] = generate_noise_samples(num_samples, noise_spec, sample_rate)
                input_signal_memmap = input_signal
            else:
                input_signal = generate_noise_samples(num_samples, noise_spec, sample_rate)
        else:
            data, _ = sf.read(input_audio_path)
            input_signal = data[:, 0] if data.ndim > 1 else data

        b_warmth, a_warmth = signal.butter(1, 10000, btype="low", fs=sample_rate)
        input_signal = signal.filtfilt(b_warmth, a_warmth, input_signal)
        b_hpf, a_hpf = signal.butter(2, 50, btype="high", fs=sample_rate)
        input_signal = signal.filtfilt(b_hpf, a_hpf, input_signal)
        input_signal = input_signal / (np.max(np.abs(input_signal)) + 1e-8) * 0.8

        rms_in = np.sqrt(np.mean(input_signal ** 2))
        if rms_in < 1e-8:
            rms_in = 1e-8

        intra_phase_rad = np.deg2rad(intra_phase_offset_deg)
        right_channel_phase_offset_rad = np.deg2rad(lfo_phase_offset_deg)

        left_output = apply_deep_swept_notches(
            input_signal,
            sample_rate,
            lfo_freq,
            filter_sweeps,
            notch_q,
            cascade_count,
            0,
            intra_phase_rad,
            lfo_waveform,
            use_memmap=memory_efficient,
        )

        right_output = apply_deep_swept_notches(
            input_signal,
            sample_rate,
            lfo_freq,
            filter_sweeps,
            notch_q,
            cascade_count,
            right_channel_phase_offset_rad,
            intra_phase_rad,
            lfo_waveform,
            use_memmap=memory_efficient,
        )

        if memory_efficient and isinstance(left_output, np.memmap):
            rms_left = _compute_rms_memmap(left_output)
        else:
            rms_left = np.sqrt(np.mean(left_output ** 2))
        if rms_left > 1e-8:
            left_output *= rms_in / rms_left

        if memory_efficient and isinstance(right_output, np.memmap):
            rms_right = _compute_rms_memmap(right_output)
        else:
            rms_right = np.sqrt(np.mean(right_output ** 2))
        if rms_right > 1e-8:
            right_output *= rms_in / rms_right

        stereo_output = np.stack((left_output, right_output), axis=-1)

        if static_notches:
            stereo_output = _apply_static_notches(stereo_output, sample_rate, static_notches)

        max_val = np.max(np.abs(stereo_output))
        if max_val > 0.95:
            stereo_output = np.clip(stereo_output, -0.95, 0.95)
        elif max_val > 0:
            stereo_output = stereo_output / max_val * 0.95

        return stereo_output, time.time() - start_time
    finally:
        _safe_close_memmap(input_signal_memmap)
        _safe_remove(input_tmp_name)


# ------------------------ RESTORED: TRANSITION VERSION ------------------------
def _generate_swept_notch_arrays_transition(
    duration_seconds,
    sample_rate,
    start_lfo_freq,
    end_lfo_freq,
    start_filter_sweeps,
    end_filter_sweeps,
    start_notch_q,
    end_notch_q,
    start_cascade_count,
    end_cascade_count,
    start_lfo_phase_offset_deg,
    end_lfo_phase_offset_deg,
    start_intra_phase_offset_deg,
    end_intra_phase_offset_deg,
    input_audio_path,
    noise_spec,
    lfo_waveform,
    initial_offset,
    transition_duration,
    transition_curve,
    memory_efficient,
    n_jobs,
    static_notches=None,
):
    """Internal helper generating swept notch noise with parameter transitions."""
    # Defensive normalization to handle malformed inputs from saved presets/UI.
    lfo_waveform = str(lfo_waveform or "sine").lower()

    if start_filter_sweeps is None:
        start_filter_sweeps = [(1000, 10000)]
    if end_filter_sweeps is None:
        end_filter_sweeps = start_filter_sweeps

    num_sweeps = len(start_filter_sweeps)

    if isinstance(start_notch_q, (int, float)):
        start_notch_q = [float(start_notch_q)] * num_sweeps
    else:
        start_notch_q = list(start_notch_q)
    if isinstance(end_notch_q, (int, float)):
        end_notch_q = [float(end_notch_q)] * num_sweeps
    else:
        end_notch_q = list(end_notch_q)

    if isinstance(start_cascade_count, int):
        start_cascade_count = [int(start_cascade_count)] * num_sweeps
    else:
        start_cascade_count = list(start_cascade_count)
    if isinstance(end_cascade_count, int):
        end_cascade_count = [int(end_cascade_count)] * num_sweeps
    else:
        end_cascade_count = list(end_cascade_count)

    if (
        len(start_notch_q) != num_sweeps
        or len(end_notch_q) != num_sweeps
        or len(start_cascade_count) != num_sweeps
        or len(end_cascade_count) != num_sweeps
    ):
        raise ValueError("Length mismatch between sweep parameters")

    start_time = time.time()
    input_signal_memmap = None
    input_tmp_name = None
    try:
        if input_audio_path is None:
            num_samples = int(duration_seconds * sample_rate)
            if memory_efficient:
                tmp_input = tempfile.NamedTemporaryFile(delete=False)
                input_tmp_name = tmp_input.name
                tmp_input.close()
                input_signal = np.memmap(input_tmp_name, dtype=np.float32, mode="w+", shape=num_samples)
                input_signal[:] = generate_noise_samples(num_samples, noise_spec, sample_rate)
                input_signal_memmap = input_signal
            else:
                input_signal = generate_noise_samples(num_samples, noise_spec, sample_rate)
        else:
            data, _ = sf.read(input_audio_path)
            input_signal = data[:, 0] if data.ndim > 1 else data

        b_warmth, a_warmth = signal.butter(1, 10000, btype="low", fs=sample_rate)
        input_signal = signal.filtfilt(b_warmth, a_warmth, input_signal)
        b_hpf, a_hpf = signal.butter(2, 50, btype="high", fs=sample_rate)
        input_signal = signal.filtfilt(b_hpf, a_hpf, input_signal)
        input_signal = input_signal / (np.max(np.abs(input_signal)) + 1e-8) * 0.8

        rms_in = np.sqrt(np.mean(input_signal ** 2))
        if rms_in < 1e-8:
            rms_in = 1e-8

        num_samples = len(input_signal)
        t = np.arange(num_samples) / sample_rate
        alpha = calculate_transition_alpha(
            duration_seconds,
            sample_rate,
            initial_offset,
            transition_duration,
            transition_curve,
        )
        if len(alpha) != num_samples:
            alpha = np.interp(
                np.linspace(0, 1, num_samples),
                np.linspace(0, 1, len(alpha)),
                alpha,
            )

        lfo_freq_array = start_lfo_freq + (end_lfo_freq - start_lfo_freq) * alpha
        phase_base = np.cumsum(2 * np.pi * lfo_freq_array / sample_rate)

        if lfo_waveform.lower() == "triangle":
            base_wave_fn = lambda ph: signal.sawtooth(ph, width=0.5)
        elif lfo_waveform.lower() == "sine":
            base_wave_fn = np.cos
        else:
            raise ValueError(
                f"Unsupported LFO waveform: {lfo_waveform}. Choose 'sine' or 'triangle'."
            )

        right_phase_rad = np.deg2rad(
            start_lfo_phase_offset_deg
            + (end_lfo_phase_offset_deg - start_lfo_phase_offset_deg) * alpha
        )
        intra_phase_rad = np.deg2rad(
            start_intra_phase_offset_deg
            + (end_intra_phase_offset_deg - start_intra_phase_offset_deg) * alpha
        )

        lfo_left = base_wave_fn(phase_base)
        lfo_left_2 = base_wave_fn(phase_base + intra_phase_rad)
        lfo_right = base_wave_fn(phase_base + right_phase_rad)
        lfo_right_2 = base_wave_fn(phase_base + right_phase_rad + intra_phase_rad)

        min_arrays = []
        max_arrays = []
        q_arrays = []
        casc_arrays = []
        for idx in range(num_sweeps):
            s_min, s_max = start_filter_sweeps[idx]
            e_min, e_max = end_filter_sweeps[idx]
            min_arrays.append(s_min + (e_min - s_min) * alpha)
            max_arrays.append(s_max + (e_max - s_max) * alpha)
            q_arrays.append(start_notch_q[idx] + (end_notch_q[idx] - start_notch_q[idx]) * alpha)
            casc_arrays.append(start_cascade_count[idx] + (end_cascade_count[idx] - start_cascade_count[idx]) * alpha)

        left_output = _apply_deep_swept_notches_varying(
            input_signal,
            sample_rate,
            lfo_left,
            min_arrays,
            max_arrays,
            q_arrays,
            casc_arrays,
            use_memmap=memory_efficient,
        )
        left_output = _apply_deep_swept_notches_varying(
            left_output,
            sample_rate,
            lfo_left_2,
            min_arrays,
            max_arrays,
            q_arrays,
            casc_arrays,
            use_memmap=memory_efficient,
        )

        right_output = _apply_deep_swept_notches_varying(
            input_signal,
            sample_rate,
            lfo_right,
            min_arrays,
            max_arrays,
            q_arrays,
            casc_arrays,
            use_memmap=memory_efficient,
        )
        right_output = _apply_deep_swept_notches_varying(
            right_output,
            sample_rate,
            lfo_right_2,
            min_arrays,
            max_arrays,
            q_arrays,
            casc_arrays,
            use_memmap=memory_efficient,
        )

        if memory_efficient and isinstance(left_output, np.memmap):
            rms_left = _compute_rms_memmap(left_output)
        else:
            rms_left = np.sqrt(np.mean(left_output ** 2))
        if rms_left > 1e-8:
            left_output *= rms_in / rms_left

        if memory_efficient and isinstance(right_output, np.memmap):
            rms_right = _compute_rms_memmap(right_output)
        else:
            rms_right = np.sqrt(np.mean(right_output ** 2))
        if rms_right > 1e-8:
            right_output *= rms_in / rms_right

        stereo_output = np.stack((left_output, right_output), axis=-1)

        if static_notches:
            stereo_output = _apply_static_notches(stereo_output, sample_rate, static_notches)

        max_val = np.max(np.abs(stereo_output))
        if max_val > 0.95:
            stereo_output = np.clip(stereo_output, -0.95, 0.95)
        elif max_val > 0:
            stereo_output = stereo_output / max_val * 0.95

        return stereo_output, time.time() - start_time
    finally:
        _safe_close_memmap(input_signal_memmap)
        _safe_remove(input_tmp_name)


def generate_swept_notch_pink_sound(
    filename="swept_notch_sound.wav",
    duration_seconds=60,
    sample_rate=DEFAULT_SAMPLE_RATE,
    lfo_freq=DEFAULT_LFO_FREQ,
    filter_sweeps=None,
    notch_q=25,
    cascade_count=10,
    lfo_phase_offset_deg=90,
    intra_phase_offset_deg=0,
    input_audio_path=None,
    noise_type="pink",
    lfo_waveform="sine",
    memory_efficient=False,
    n_jobs=1,
    static_notches=None,
):
    """Generate swept notch noise and save to ``filename``."""
    stereo_output, total_time = _generate_swept_notch_arrays(
        duration_seconds,
        sample_rate,
        lfo_freq,
        filter_sweeps,
        notch_q,
        cascade_count,
        lfo_phase_offset_deg,
        intra_phase_offset_deg,
        input_audio_path,
        noise_type,
        lfo_waveform,
        memory_efficient,
        n_jobs,
        static_notches,
    )
    try:
        output_dir = os.path.dirname(filename)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)
        sf.write(filename, stereo_output, sample_rate, subtype="PCM_16")
        print(f"\nSuccessfully generated and saved to '{filename}' in {total_time:.2f} seconds.")
    except Exception as e:
        print(f"Error saving audio file: {e}")


# --------------- RESTORED PUBLIC WRAPPER (TRANSITION) ---------------
def generate_swept_notch_pink_sound_transition(
    filename="swept_notch_sound_transition.wav",
    duration_seconds=60,
    sample_rate=DEFAULT_SAMPLE_RATE,
    start_lfo_freq=DEFAULT_LFO_FREQ,
    end_lfo_freq=DEFAULT_LFO_FREQ,
    start_filter_sweeps=None,
    end_filter_sweeps=None,
    start_notch_q=25,
    end_notch_q=25,
    start_cascade_count=10,
    end_cascade_count=10,
    start_lfo_phase_offset_deg=90,
    end_lfo_phase_offset_deg=90,
    start_intra_phase_offset_deg=0,
    end_intra_phase_offset_deg=0,
    input_audio_path=None,
    noise_type="pink",
    lfo_waveform="sine",
    initial_offset=0.0,
    transition_duration=None,
    transition_curve="linear",
    memory_efficient=False,
    n_jobs=1,
    static_notches=None,
):
    """Generate swept notch noise with parameters smoothly transitioning from startend."""
    stereo_output, total_time = _generate_swept_notch_arrays_transition(
        duration_seconds,
        sample_rate,
        start_lfo_freq,
        end_lfo_freq,
        start_filter_sweeps,
        end_filter_sweeps if end_filter_sweeps is not None else start_filter_sweeps,
        start_notch_q,
        end_notch_q,
        start_cascade_count,
        end_cascade_count,
        start_lfo_phase_offset_deg,
        end_lfo_phase_offset_deg,
        start_intra_phase_offset_deg,
        end_intra_phase_offset_deg,
        input_audio_path,
        noise_type,
        lfo_waveform,
        initial_offset,
        transition_duration,
        transition_curve,
        memory_efficient,
        n_jobs,
        static_notches,
    )
    try:
        output_dir = os.path.dirname(filename)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)
        sf.write(filename, stereo_output, sample_rate, subtype="PCM_16")
        print(f"\nSuccessfully generated and saved to '{filename}' in {total_time:.2f} seconds.")
    except Exception as e:
        print(f"Error saving audio file: {e}")


# =========================
# Step voice wrappers
# =========================
def noise_generator(
    duration,
    sample_rate=DEFAULT_SAMPLE_RATE,
    noise_type="pink",
    lfo_waveform="sine",
    lfo_freq=DEFAULT_LFO_FREQ,
    sweeps=None,
    notch_q=None,
    cascade_count=None,
    lfo_phase_offset_deg=90.0,
    intra_phase_offset_deg=0.0,
    input_audio_path=None,
    amp=0.25,
    amp_left=None,
    amp_right=None,
    fade_in=0.0,
    fade_out=0.0,
    amp_envelope=None,
    memory_efficient=False,
    n_jobs=1,
    static_notches=None,
    **extra_params,
):
    """Generate swept-notch coloured noise for a single step."""

    duration = float(duration)
    sample_rate = float(sample_rate)
    n_jobs = max(1, int(n_jobs))

    sweeps_cfg, q_vals, casc_vals = _prepare_static_sweeps(sweeps)

    if notch_q is not None:
        if isinstance(notch_q, (list, tuple)):
            q_vals = [float(_safe_float(q, 25.0)) for q in notch_q]
        else:
            q_vals = [float(_safe_float(notch_q, 25.0))] * len(sweeps_cfg)

    if cascade_count is not None:
        if isinstance(cascade_count, (list, tuple)):
            casc_vals = [int(max(1, _safe_int(c, 10))) for c in cascade_count]
        else:
            casc_vals = [int(max(1, _safe_int(cascade_count, 10)))] * len(sweeps_cfg)

    if len(sweeps_cfg) == 0:
        notch_arg = []
        casc_arg = []
    else:
        notch_arg = q_vals if len(q_vals) > 1 else q_vals[0]
        casc_arg = casc_vals if len(casc_vals) > 1 else casc_vals[0]

    stereo_output, _ = _generate_swept_notch_arrays(
        duration,
        sample_rate,
        lfo_freq,
        sweeps_cfg,
        notch_arg,
        casc_arg,
        lfo_phase_offset_deg,
        intra_phase_offset_deg,
        input_audio_path or None,
        noise_type,
        lfo_waveform,
        bool(memory_efficient),
        n_jobs,
        static_notches,
        initial_offset=float(extra_params.get("initial_offset", 0.0)),
    )

    audio = np.array(stereo_output, dtype=np.float32, copy=True)
    if audio.ndim == 1:
        audio = np.column_stack((audio, audio))

    num_samples = audio.shape[0]
    if num_samples == 0:
        return audio.reshape(0, 2), {}

    env = _build_noise_envelope(num_samples, sample_rate, fade_in, fade_out, amp_envelope)

    base_amp = _safe_float(amp, 1.0)
    left_amp = _safe_float(amp_left, base_amp) if amp_left is not None else base_amp
    right_amp = _safe_float(amp_right, base_amp) if amp_right is not None else base_amp

    gains = env.astype(np.float32)
    audio[:, 0] *= gains * float(left_amp)
    audio[:, 1] *= gains * float(right_amp)

    audio = np.clip(audio, -1.0, 1.0)

    if not np.isfinite(audio).all():
        bad_count = np.count_nonzero(~np.isfinite(audio))
        print(
            f"Warning: noise_generator produced {bad_count} non-finite samples; replacing with zeros."
        )
        audio = np.nan_to_num(audio, nan=0.0, posinf=0.0, neginf=0.0)

    if bool(extra_params.get("spatialEnable", False)):
        theta_deg, distance_m = generate_azimuth_trajectory(
            duration,
            sample_rate,
            segments=extra_params.get(
                "spatialTrajectory",
                [
                    {
                        "mode": "oscillate",
                        "center_deg": 0,
                        "extent_deg": 75,
                        "period_s": 20.0,
                        "distance_m": [1.0, 1.4],
                        "seconds": duration,
                    }
                ],
            ),
        )
        audio = spatialize_binaural_mid_only(
            audio.astype(np.float32),
            float(sample_rate),
            theta_deg,
            distance_m,
            ild_enable=int(extra_params.get("spatialUseIld", 1)),
            ear_angle_deg=float(extra_params.get("spatialEarAngleDeg", 30.0)),
            head_radius_m=float(extra_params.get("spatialHeadRadiusM", 0.0875)),
            itd_scale=float(extra_params.get("spatialItdScale", 1.0)),
            ild_max_db=float(extra_params.get("spatialIldMaxDb", 1.5)),
            ild_xover_hz=float(extra_params.get("spatialIldXoverHz", 700.0)),
            ref_distance_m=float(extra_params.get("spatialRefDistanceM", 1.0)),
            rolloff=float(extra_params.get("spatialRolloff", 1.0)),
            hf_roll_db_per_m=float(extra_params.get("spatialHfRollDbPerM", 0.0)),
            dz_theta_ms=float(extra_params.get("spatialDezipperThetaMs", 60.0)),
            dz_dist_ms=float(extra_params.get("spatialDezipperDistMs", 80.0)),
            decoder=0 if str(extra_params.get("spatialDecoder", "itd_head")).lower() != "foa_cardioid" else 1,
            min_distance_m=float(extra_params.get("spatialMinDistanceM", 0.1)),
            max_deg_per_s=float(extra_params.get("spatialMaxDegPerS", 90.0)),
            max_delay_step_samples=float(extra_params.get("spatialMaxDelayStepSamples", 0.02)),
            interp_mode=int(extra_params.get("spatialInterp", 1)),
        )
        audio = np.clip(audio, -1.0, 1.0)

        if not np.isfinite(audio).all():
            bad_count = np.count_nonzero(~np.isfinite(audio))
            print(
                f"Warning: noise_generator produced {bad_count} non-finite samples after spatialization; replacing with zeros."
            )
            audio = np.nan_to_num(audio, nan=0.0, posinf=0.0, neginf=0.0)

    return audio, {}


def noise_generator_transition(
    duration,
    sample_rate=DEFAULT_SAMPLE_RATE,
    noise_type="pink",
    lfo_waveform="sine",
    start_lfo_freq=DEFAULT_LFO_FREQ,
    end_lfo_freq=DEFAULT_LFO_FREQ,
    sweeps=None,
    start_notch_q=None,
    end_notch_q=None,
    start_cascade_count=None,
    end_cascade_count=None,
    start_lfo_phase_offset_deg=90.0,
    end_lfo_phase_offset_deg=90.0,
    start_intra_phase_offset_deg=0.0,
    end_intra_phase_offset_deg=0.0,
    initial_offset=0.0,
    transition_duration=None,
    curve="linear",
    input_audio_path=None,
    start_amp=0.25,
    end_amp=None,
    start_amp_left=None,
    end_amp_left=None,
    start_amp_right=None,
    end_amp_right=None,
    fade_in=0.0,
    fade_out=0.0,
    amp_envelope=None,
    memory_efficient=False,
    n_jobs=1,
    static_notches=None,
    **extra_params,
):
    """Transitioning version of :func:`noise_generator`."""

    duration = float(duration)
    sample_rate = float(sample_rate)
    n_jobs = max(1, int(n_jobs))
    if transition_duration is None and "post_offset" in extra_params:
        transition_duration = extra_params.pop("post_offset")
    if transition_duration is not None:
        transition_duration = float(transition_duration)

    (
        start_sweeps,
        end_sweeps,
        start_q_vals,
        end_q_vals,
        start_casc_vals,
        end_casc_vals,
    ) = _prepare_transition_sweeps(sweeps)

    if start_notch_q is not None:
        if isinstance(start_notch_q, (list, tuple)):
            start_q_vals = [float(_safe_float(q, 25.0)) for q in start_notch_q]
        else:
            start_q_vals = [float(_safe_float(start_notch_q, 25.0))] * len(start_sweeps)

    if end_notch_q is not None:
        if isinstance(end_notch_q, (list, tuple)):
            end_q_vals = [float(_safe_float(q, start_q_vals[i])) for i, q in enumerate(end_notch_q)]
        else:
            end_q_vals = [float(_safe_float(end_notch_q, start_q_vals[i])) for i in range(len(start_q_vals))]

    if start_cascade_count is not None:
        if isinstance(start_cascade_count, (list, tuple)):
            start_casc_vals = [int(max(1, _safe_int(c, 10))) for c in start_cascade_count]
        else:
            start_casc_vals = [int(max(1, _safe_int(start_cascade_count, 10)))] * len(start_sweeps)

    if end_cascade_count is not None:
        if isinstance(end_cascade_count, (list, tuple)):
            end_casc_vals = [int(max(1, _safe_int(c, start_casc_vals[i]))) for i, c in enumerate(end_cascade_count)]
        else:
            end_casc_vals = [int(max(1, _safe_int(end_cascade_count, start_casc_vals[i])))] * len(start_sweeps)

    if len(start_sweeps) == 0:
        start_notch_arg = []
        end_notch_arg = []
        start_casc_arg = []
        end_casc_arg = []
    else:
        start_notch_arg = start_q_vals if len(start_q_vals) > 1 else start_q_vals[0]
        end_notch_arg = end_q_vals if len(end_q_vals) > 1 else end_q_vals[0]
        start_casc_arg = start_casc_vals if len(start_casc_vals) > 1 else start_casc_vals[0]
        end_casc_arg = end_casc_vals if len(end_casc_vals) > 1 else end_casc_vals[0]

    stereo_output, _ = _generate_swept_notch_arrays_transition(
        duration,
        sample_rate,
        start_lfo_freq,
        end_lfo_freq,
        start_sweeps,
        end_sweeps,
        start_notch_arg,
        end_notch_arg,
        start_casc_arg,
        end_casc_arg,
        start_lfo_phase_offset_deg,
        end_lfo_phase_offset_deg,
        start_intra_phase_offset_deg,
        end_intra_phase_offset_deg,
        input_audio_path or None,
        noise_type,
        lfo_waveform,
        initial_offset,
        transition_duration,
        curve,
        bool(memory_efficient),
        n_jobs,
        static_notches,
    )

    audio = np.array(stereo_output, dtype=np.float32, copy=True)
    if audio.ndim == 1:
        audio = np.column_stack((audio, audio))

    num_samples = audio.shape[0]
    if num_samples == 0:
        return audio.reshape(0, 2)

    alpha = calculate_transition_alpha(
        duration, sample_rate, initial_offset, transition_duration, curve
    )
    if alpha.size == 0:
        alpha = np.zeros(num_samples, dtype=np.float64)
    elif alpha.size != num_samples:
        positions = np.linspace(0.0, 1.0, num_samples, endpoint=False)
        alpha = np.interp(
            positions,
            np.linspace(0.0, 1.0, alpha.size, endpoint=False),
            alpha,
            left=alpha[0],
            right=alpha[-1],
        )

    base_start_amp = _safe_float(start_amp, 1.0)
    base_end_amp = _safe_float(end_amp, base_start_amp)

    left_start, left_end = _resolve_channel_amp(base_start_amp, base_end_amp, start_amp_left, end_amp_left)
    right_start, right_end = _resolve_channel_amp(base_start_amp, base_end_amp, start_amp_right, end_amp_right)

    alpha = alpha.astype(np.float32)
    left_curve = left_start + (left_end - left_start) * alpha
    right_curve = right_start + (right_end - right_start) * alpha

    env = _build_noise_envelope(num_samples, sample_rate, fade_in, fade_out, amp_envelope).astype(np.float32)

    audio[:, 0] *= env * left_curve
    audio[:, 1] *= env * right_curve

    audio = np.clip(audio, -1.0, 1.0)

    if not np.isfinite(audio).all():
        bad_count = np.count_nonzero(~np.isfinite(audio))
        print(
            f"Warning: noise_generator_transition produced {bad_count} non-finite samples; replacing with zeros."
        )
        audio = np.nan_to_num(audio, nan=0.0, posinf=0.0, neginf=0.0)

    if bool(extra_params.get("spatialEnable", False)):
        theta_deg, distance_m = generate_azimuth_trajectory(
            duration,
            sample_rate,
            segments=extra_params.get(
                "spatialTrajectory",
                [
                    {
                        "mode": "oscillate",
                        "center_deg": 0,
                        "extent_deg": 75,
                        "period_s": 20.0,
                        "distance_m": [1.0, 1.4],
                        "seconds": duration,
                    }
                ],
            ),
        )
        audio = spatialize_binaural_mid_only(
            audio.astype(np.float32),
            float(sample_rate),
            theta_deg,
            distance_m,
            ild_enable=int(extra_params.get("spatialUseIld", 1)),
            ear_angle_deg=float(extra_params.get("spatialEarAngleDeg", 30.0)),
            head_radius_m=float(extra_params.get("spatialHeadRadiusM", 0.0875)),
            itd_scale=float(extra_params.get("spatialItdScale", 1.0)),
            ild_max_db=float(extra_params.get("spatialIldMaxDb", 1.5)),
            ild_xover_hz=float(extra_params.get("spatialIldXoverHz", 700.0)),
            ref_distance_m=float(extra_params.get("spatialRefDistanceM", 1.0)),
            rolloff=float(extra_params.get("spatialRolloff", 1.0)),
            hf_roll_db_per_m=float(extra_params.get("spatialHfRollDbPerM", 0.0)),
            dz_theta_ms=float(extra_params.get("spatialDezipperThetaMs", 60.0)),
            dz_dist_ms=float(extra_params.get("spatialDezipperDistMs", 80.0)),
            decoder=0 if str(extra_params.get("spatialDecoder", "itd_head")).lower() != "foa_cardioid" else 1,
            min_distance_m=float(extra_params.get("spatialMinDistanceM", 0.1)),
            max_deg_per_s=float(extra_params.get("spatialMaxDegPerS", 90.0)),
            max_delay_step_samples=float(extra_params.get("spatialMaxDelayStepSamples", 0.02)),
            interp_mode=int(extra_params.get("spatialInterp", 1)),
        )
        audio = np.clip(audio, -1.0, 1.0)

        if not np.isfinite(audio).all():
            bad_count = np.count_nonzero(~np.isfinite(audio))
            print(
                "Warning: noise_generator_transition produced "
                f"{bad_count} non-finite samples after spatialization; replacing with zeros."
            )
            audio = np.nan_to_num(audio, nan=0.0, posinf=0.0, neginf=0.0)

    return audio, {}


# =======================================================
# NEW: Flanged noise progression (freeze  ramp  hold)
# =======================================================
def generate_flanged_noise_progression(
    filename="flanged_noise_progression.wav",
    duration_seconds=120.0,
    sample_rate=DEFAULT_SAMPLE_RATE,
    noise_type="pink",
    # macro envelopes (start -> end)
    start_rate_hz=0.32,
    end_rate_hz=0.06,
    start_center_ms=2.0,
    end_center_ms=0.9,
    start_depth_ms=1.5,
    end_depth_ms=0.4,
    start_mix=0.35,
    end_mix=0.22,
    start_feedback=0.40,
    end_feedback=0.18,
    # one-way behavior and stop conditions (direction is in the FREQUENCY domain)
    direction="up",  # "up" => f0 increases; "down" => f0 decreases
    ramp_seconds=None,  # reach the end by this wall-clock time (includes pauses)
    stop_when_spacing_hz=None,  # stop when f hits this (Hz)
    stop_when_first_notch_hz=None,  # stop when f0 hits this (Hz)
    stop_at_peak=False,  # stop where triangle would turn around (first extreme)
    freeze_seconds=None,  # total file: initial_freeze + ramp + freeze
    # initial/final freeze
    initial_freeze_seconds=0.0,  # pre-hold before any transition
    final_freeze_at_last_sec=0.0,  # optional tail hold (parity)
    # pause sequencing
    run_range=(2.5, 7.0),
    hold_range=(1.0, 3.0),
    smooth_ms=25.0,
    rng_seed=42,
    pauses_during_ramp=True,
    pause_free_tail_frac=0.25,  # last fraction of ramp with pauses disabled
    # smoothing + mitigation
    delay_slew_ms=12.0,
    ease_to_hold_ms=200.0,  # minimum-jerk blend into the plateau
    mix_slew_ms=15.0,
    feedback_slew_ms=25.0,
    interp="linear",  # "linear" or "cubic"
    # linearization / shaping
    sweep_domain="delay",  # "delay" | "f0" | "spacing" | "logf0"
    progress_gamma=1.0,  # >1 straightens the late portion of the ramp
    # --- NEW: Crest-cap / Leveler controls ---
    crest_cap_db=12.0,
    crest_attack_ms=3.0,
    crest_release_ms=80.0,
    crest_peak_window_ms=10.0,
    crest_rms_window_ms=200.0,
    crest_hp_weight_hz=60.0,
    leveler_target_db=None,           # e.g., -12.0 to enable; None disables
    leveler_window_ms=300.0,
    leveler_attack_ms=40.0,
    leveler_release_ms=200.0,
    leveler_max_up_db=6.0,
    leveler_max_down_db=12.0,
    leveler_hp_weight_hz=60.0,
    # --- Post-processing ---
    normalize_rms_db=None,  # e.g. -18.0; None disables global RMS normalization
    tp_ceiling_db=None,  # e.g. -1.0; None disables limiter
    limiter_lookahead_ms=2.0,
    limiter_release_ms=60.0,
    limiter_oversample=4,
    softclip_drive_db=0.0,  # >0 to add gentle tanh saturation after limiting
    output_subtype="PCM_24",  # "PCM_16" | "PCM_24" | "FLOAT"
):
    """
    Flanged-noise progression with:
      - explicit piecewise _ms = [initial freeze | ramp | final hold],
      - pauses in early ramp region, *pause-free tail* that guarantees s==1 at end,
      - stop-at-peak and stop-when-f0/f,
      - endpoint easing, control slews, and cubic interpolation option,
      - sweep_domain to linearize in 'f0'/'spacing'/'logf0', and progress_gamma shaping,
      - crest-factor cap + optional short-term leveler,
      - optional RMS normalization + true-peak limiting (+ soft-clip).
    """
    fs = int(sample_rate)

    # ------------------ helpers ------------------
    def _alpha_from_ms(ms):  # one-pole coeff
        return np.exp(-1.0 / max(1.0, (ms * 1e-3) * fs))

    def _one_pole_smoother(x, smooth_ms):
        if smooth_ms <= 0:
            return x.astype(np.float32, copy=False)
        a = _alpha_from_ms(smooth_ms)
        y = np.empty_like(x, dtype=np.float32)
        s = float(x[0])
        for i in range(x.shape[0]):
            s = a * s + (1.0 - a) * float(x[i])
            y[i] = s
        return y

    def _make_gate(n, run_rng, hold_rng, edge_ms, seed):
        if n <= 0:
            return np.zeros(0, dtype=np.float32)
        rng = np.random.default_rng(seed)
        out = np.zeros(n, dtype=np.float32)
        i, state = 0, 1
        while i < n:
            dur = rng.uniform(*(run_rng if state == 1 else hold_rng))
            L = max(1, int(dur * fs))
            j = min(n, i + L)
            out[i:j] = 1.0 if state == 1 else 0.0
            i = j
            state ^= 1
        Ls = int(max(3, round(edge_ms * 1e-3 * fs)))
        if Ls % 2 == 0:
            Ls += 1
        if Ls > 3:
            win = np.hanning(Ls).astype(np.float32)
            win /= max(win.sum(), 1e-12)
            out = np.convolve(out, win, mode="same").astype(np.float32)
        return out

    def _smoothstep5(u):
        return (u * u * u) * (10.0 + u * (-15.0 + 6.0 * u))  # C2 smooth

    def _read_linear(buf, read_pos, max_delay):
        i0 = int(np.floor(read_pos)) % max_delay
        i1 = (i0 + 1) % max_delay
        frac = read_pos - np.floor(read_pos)
        return (1.0 - frac) * buf[i0] + frac * buf[i1]

    def _read_cubic(buf, read_pos, max_delay):
        i1 = int(np.floor(read_pos))
        t_ = read_pos - i1
        i0 = (i1 - 1) % max_delay
        i1 = i1 % max_delay
        i2 = (i1 + 1) % max_delay
        i3 = (i1 + 2) % max_delay
        x0, x1, x2, x3 = buf[i0], buf[i1], buf[i2], buf[i3]
        a0 = -0.5 * x0 + 1.5 * x1 - 1.5 * x2 + 0.5 * x3
        a1 = x0 - 2.5 * x1 + 2.0 * x2 - 0.5 * x3
        a2 = -0.5 * x0 + 0.5 * x2
        a3 = x1
        return ((a0 * t_ + a1) * t_ + a2) * t_ + a3

    # ---- compute total duration if ramp-based ----
    has_ramp = ramp_seconds is not None
    n_init = int(max(0.0, float(initial_freeze_seconds)) * fs)
    n_ramp = int((ramp_seconds if has_ramp else 0.0) * fs)
    n_tail = int((freeze_seconds if freeze_seconds is not None else 0.0) * fs)

    if has_ramp:
        duration_seconds = (initial_freeze_seconds or 0.0) + float(ramp_seconds) + (freeze_seconds or 0.0)

    n_total = int(duration_seconds * fs)
    n_init = min(n_init, n_total)
    n_ramp = min(n_ramp, max(0, n_total - n_init))
    n_tail = min(n_tail, max(0, n_total - n_init - n_ramp))
    n_rest = max(0, n_total - (n_init + n_ramp + n_tail))
    n_tail += n_rest  # absorb rounding error

    print(f"[progression] segments: init={n_init/fs:.3f}s, ramp={n_ramp/fs:.3f}s, hold={n_tail/fs:.3f}s")

    # ---- source & macro envelopes (for mix/feedback; delay is piecewise below) ----
    t = np.arange(n_total, dtype=np.float32) / fs
    x = generate_noise_samples(n_total, noise_type, fs).astype(np.float32)

    def _lerp_time(start, end):
        return np.interp(t, [0.0, duration_seconds], [start, end]).astype(np.float32)

    rate_env = _lerp_time(start_rate_hz, end_rate_hz)  # currently unused, kept for completeness
    mix_env = _lerp_time(start_mix, end_mix)
    fb_env = _lerp_time(start_feedback, end_feedback)

    # ---- compute start/end extremes  (ms) from knobs + direction ----
    if direction.lower() == "up":
        tau_start_ms = float(start_center_ms + start_depth_ms)  # max delay  lowest f0
        tau_end_ms = float(end_center_ms - end_depth_ms)  # min delay  highest f0
    else:
        tau_start_ms = float(start_center_ms - start_depth_ms)  # min delay  highest f0
        tau_end_ms = float(end_center_ms + end_depth_ms)  # max delay  lowest f0

    if tau_start_ms <= 0.0 or tau_end_ms <= 0.0:
        raise ValueError(
            f"Invalid extremes: _start={tau_start_ms:.6f} ms, _end={tau_end_ms:.6f} ms. "
            "Choose center/depth so both are positive."
        )

    # ================== PIECEWISE _ms TARGET ==================
    tau_ms_target = np.empty(n_total, dtype=np.float32)

    # -- 1) INITIAL FREEZE: constant  at start extreme --
    if n_init > 0:
        tau_ms_target[:n_init] = tau_start_ms

    # -- 2) RAMP: create progress s[0,1] over n_ramp samples (pauses in first part, pause-free tail) --
    idx_start_ramp = n_init
    idx_end_ramp = n_init + n_ramp

    if n_ramp > 0:
        pft = float(np.clip(pause_free_tail_frac, 0.0, 1.0))
        cutoff = int(np.floor(n_ramp * (1.0 - pft)))
        cutoff = max(0, min(cutoff, n_ramp))

        # Part A: pauses region  rescaled to alpha progress at cutoff
        if cutoff > 0 and pauses_during_ramp:
            g = _make_gate(cutoff, run_range, hold_range, smooth_ms, rng_seed)
            run_mask = (g >= 0.5).astype(np.float32)
            cum_run = np.cumsum(run_mask)
            total_active = float(cum_run[-1]) if cutoff > 0 else 1.0
            if total_active < 1.0:
                total_active = 1.0
            alpha = cutoff / float(n_ramp)
            s_first = alpha * (cum_run / total_active).astype(np.float32)
        elif cutoff > 0:
            alpha = cutoff / float(n_ramp)
            idx_first = np.arange(cutoff, dtype=np.float32)
            denom = max(1.0, cutoff - 1.0)
            s_first = alpha * (idx_first / denom)
        else:
            s_first = np.zeros(0, dtype=np.float32)
            alpha = 0.0

        # Part B: pause-free tail  inclusive normalization ensures last ramp sample hits s==1.0
        tail = n_ramp - cutoff
        if tail > 0:
            idx_tail = np.arange(tail, dtype=np.float32)
            s_second = alpha + (1.0 - alpha) * ((idx_tail + 1.0) / float(tail))
        else:
            s_second = np.zeros(0, dtype=np.float32)

        s_ramp = np.concatenate([s_first, s_second], axis=0)
        if progress_gamma != 1.0:
            s_ramp = np.power(np.clip(s_ramp, 0.0, 1.0), float(progress_gamma)).astype(np.float32)

        # Map s_ramp to  in desired sweep domain
        if sweep_domain.lower() == "delay":
            tau_ramp_ms = (1.0 - s_ramp) * tau_start_ms + s_ramp * tau_end_ms
        elif sweep_domain.lower() == "spacing":
            df_start = 1000.0 / tau_start_ms
            df_end = 1000.0 / tau_end_ms
            df = (1.0 - s_ramp) * df_start + s_ramp * df_end
            tau_ramp_ms = 1000.0 / np.maximum(df, 1e-9)
        elif sweep_domain.lower() == "f0":
            f0_start = 500.0 / tau_start_ms
            f0_end = 500.0 / tau_end_ms
            f0 = (1.0 - s_ramp) * f0_start + s_ramp * f0_end
            tau_ramp_ms = 500.0 / np.maximum(f0, 1e-9)
        elif sweep_domain.lower() == "logf0":
            f0_start = 500.0 / tau_start_ms
            f0_end = 500.0 / tau_end_ms
            log_f0 = (1.0 - s_ramp) * np.log10(f0_start) + s_ramp * np.log10(f0_end)
            f0 = np.power(10.0, log_f0).astype(np.float32)
            tau_ramp_ms = 500.0 / np.maximum(f0, 1e-9)
        else:
            raise ValueError(f"Unsupported sweep_domain: {sweep_domain}")

        # Early stop conditions  search ONLY within the ramp window
        idx_stop = None
        if (stop_when_first_notch_hz is not None) or (stop_when_spacing_hz is not None):
            tau_s = tau_ramp_ms * 1e-3
            series = (
                0.5 / np.maximum(tau_s, 1e-9)
                if (stop_when_first_notch_hz is not None)
                else 1.0 / np.maximum(tau_s, 1e-9)
            )
            target = float(
                stop_when_first_notch_hz if stop_when_first_notch_hz is not None else stop_when_spacing_hz
            )
            s0 = float(series[0])
            if np.isclose(s0, target, atol=1e-6, rtol=0.0):
                idx_stop = 0
            elif s0 < target:
                mask = series >= target
                idx_stop = int(np.argmax(mask)) if np.any(mask) else None
            else:
                mask = series <= target
                idx_stop = int(np.argmax(mask)) if np.any(mask) else None

        # Peak = last ramp sample
        idx_peak_ramp = (n_ramp - 1) if (n_ramp > 0) else None
        # Decide freeze point within ramp (local index)
        if idx_stop is not None:
            freeze_local = idx_stop
            hold_target_ms = float(tau_ramp_ms[idx_stop])
        else:
            # stop_at_peak simply means "freeze at the end of the ramp"
            freeze_local = idx_peak_ramp if stop_at_peak else idx_peak_ramp
            hold_target_ms = float(tau_end_ms)

        # Apply endpoint easing inside the ramp (blend last E ms toward hold_target_ms)
        tau_ramp_ms_eased = tau_ramp_ms.copy()
        if ease_to_hold_ms > 0 and freeze_local is not None and freeze_local > 0:
            L = int((ease_to_hold_ms * 1e-3) * fs)
            if L > 1:
                k0 = max(0, freeze_local - L)
                seg = tau_ramp_ms_eased[k0:freeze_local].copy()
                m = seg.size
                if m > 0:
                    u = np.linspace(0.0, 1.0, m, endpoint=False, dtype=np.float32)
                    w = _smoothstep5(u)
                    tau_ramp_ms_eased[k0:freeze_local] = seg * (1.0 - w) + hold_target_ms * w
                tau_ramp_ms_eased[freeze_local:] = hold_target_ms
        else:
            if freeze_local is not None:
                tau_ramp_ms_eased[freeze_local:] = hold_target_ms

        # Write ramp block into global 
        tau_ms_target[idx_start_ramp:idx_end_ramp] = tau_ramp_ms_eased

        # -- 3) FINAL HOLD: constant  == hold_target_ms --
        if n_tail > 0:
            tau_ms_target[idx_end_ramp:] = hold_target_ms
    else:
        # no ramp: fully frozen at start extreme
        tau_ms_target[:] = tau_start_ms

    # Optional extra tail freeze (parity with older interface)
    if final_freeze_at_last_sec and final_freeze_at_last_sec > 0:
        k = n_total - int(final_freeze_at_last_sec * fs)
        if 0 < k < n_total:
            tau_ms_target[k:] = tau_ms_target[k]

    # ---- Smooth delay trajectory ----
    d_ms_target = np.maximum(tau_ms_target, 1e-6)
    d_samp_target = (d_ms_target * 1e-3 * fs).astype(np.float32)
    d_samp = _one_pole_smoother(d_samp_target, delay_slew_ms)

    # ---- Render flanger (cubic optional) ----
    use_cubic = (str(interp).lower() == "cubic")
    a_mix = np.exp(-1.0 / max(1.0, (mix_slew_ms * 1e-3) * fs))
    a_fb = np.exp(-1.0 / max(1.0, (feedback_slew_ms * 1e-3) * fs))

    max_delay = int(np.ceil(float(np.max(d_samp)))) + 4
    buf = np.zeros(max_delay, dtype=np.float32)
    y = np.zeros(n_total, dtype=np.float32)
    w = 0
    mix_state = float(mix_env[0])
    fb_state = float(fb_env[0])

    for i in range(n_total):
        mix_state = a_mix * mix_state + (1.0 - a_mix) * float(mix_env[i])
        fb_state = a_fb * fb_state + (1.0 - a_fb) * float(fb_env[i])

        fb = fb_state * (y[i - 1] if i > 0 else 0.0)
        buf[w] = x[i] + fb

        read_pos = w - d_samp[i]
        while read_pos < 0:
            read_pos += max_delay

        if use_cubic:
            delayed = _read_cubic(buf, read_pos, max_delay)
        else:
            delayed = _read_linear(buf, read_pos, max_delay)

        y[i] = (1.0 - mix_state) * x[i] + mix_state * delayed
        w = (w + 1) % max_delay

    # ---------------- POST: crest cap + leveler + loudness/limiting ----------------
    y_post = y

    # (A) Crest-factor cap: tame peak jumps with same loudness
    if crest_cap_db is not None:
        y_post = crest_factor_leveler(
            y_post,
            fs,
            cap_db=crest_cap_db,
            peak_window_ms=crest_peak_window_ms,
            rms_window_ms=crest_rms_window_ms,
            attack_ms=crest_attack_ms,
            release_ms=crest_release_ms,
            hp_weight_hz=crest_hp_weight_hz,
        )

    # (B) Short-term loudness leveler (optional)
    if leveler_target_db is not None:
        y_post = loudness_leveler(
            y_post,
            fs,
            target_db=leveler_target_db,
            window_ms=leveler_window_ms,
            attack_ms=leveler_attack_ms,
            release_ms=leveler_release_ms,
            max_up_db=leveler_max_up_db,
            max_down_db=leveler_max_down_db,
            hp_weight_hz=leveler_hp_weight_hz,
        )

    # (C) Global RMS normalize (master reference)
    if normalize_rms_db is not None:
        y_post = _normalize_rms(y_post, normalize_rms_db)

    # (D) True-peak limiter
    if tp_ceiling_db is not None:
        y_post = true_peak_limiter(
            y_post,
            fs,
            ceiling_db=tp_ceiling_db,
            lookahead_ms=limiter_lookahead_ms,
            release_ms=limiter_release_ms,
            oversample=limiter_oversample,
        )

    # (E) Optional soft saturation
    if softclip_drive_db and abs(softclip_drive_db) > 1e-9:
        ceiling_for_clip = tp_ceiling_db if tp_ceiling_db is not None else -0.1
        y_post = _soft_clip_tanh(y_post, drive_db=softclip_drive_db, ceiling_db=ceiling_for_clip)

    # Write with headroom-friendly format by default
    sf.write(filename, y_post, fs, subtype=output_subtype)
    return filename


# =========================
# CLI
# =========================
def main():
    parser = argparse.ArgumentParser(
        description="Generate noise with swept notch filters (incl. transition) or flanging (including one-way progression)."
    )
    sub = parser.add_subparsers(dest="mode", required=True)

    # Simple flange (legacy)
    flange = sub.add_parser("flange", help="Apply a basic flanger to noise")
    flange.add_argument("--output", type=str, default="flanged_noise.wav")
    flange.add_argument("--duration", type=float, default=60.0)
    flange.add_argument("--noise-type", type=str, default="pink")
    flange.add_argument("--lfo-freq", type=float, default=0.1)
    flange.add_argument("--max-delay-ms", type=float, default=5.0)
    flange.add_argument("--mix", type=float, default=0.5)
    flange.add_argument("--direction", choices=["up", "down"], default="up")
    flange.add_argument("--lfo-waveform", choices=["sine", "triangle"], default="sine")

    # Notch path (static LFO params)
    notch = sub.add_parser("notch", help="Generate swept-notch filtered noise")
    notch.add_argument("--output", type=str, default="dual_sweep_triangle_lfo.wav")
    notch.add_argument("--duration", type=float, default=60.0)
    notch.add_argument("--lfo-freq", type=float, default=DEFAULT_LFO_FREQ)
    notch.add_argument("--lfo-waveform", choices=["sine", "triangle"], default="triangle")

    # NEW: one-way flange progression
    prog = sub.add_parser("flange-progression", help="One-way flanging progression with freezes, pauses, and hold.")
    prog.add_argument("--output", type=str, default="flanged_progression.wav")
    prog.add_argument("--duration", type=float, default=120.0)
    prog.add_argument("--noise-type", type=str, default="pink")

    # Macro envelopes
    prog.add_argument("--start-rate-hz", type=float, default=0.32)
    prog.add_argument("--end-rate-hz", type=float, default=0.06)
    prog.add_argument("--start-center-ms", type=float, default=2.0)
    prog.add_argument("--end-center-ms", type=float, default=0.9)
    prog.add_argument("--start-depth-ms", type=float, default=1.5)
    prog.add_argument("--end-depth-ms", type=float, default=0.4)
    prog.add_argument("--start-mix", type=float, default=0.35)
    prog.add_argument("--end-mix", type=float, default=0.22)
    prog.add_argument("--start-feedback", type=float, default=0.40)
    prog.add_argument("--end-feedback", type=float, default=0.18)

    # Direction & timing
    prog.add_argument("--direction", choices=["up", "down"], default="up")
    prog.add_argument("--ramp-seconds", type=float, default=60.0)
    prog.add_argument("--freeze-seconds", type=float, default=30.0)  # final hold
    prog.add_argument("--initial-freeze-seconds", type=float, default=0.0)

    # Pause sequencing during ramp
    prog.add_argument("--pauses-during-ramp", action="store_true", default=False)
    prog.add_argument("--run-min", type=float, default=2.5)
    prog.add_argument("--run-max", type=float, default=7.0)
    prog.add_argument("--hold-min", type=float, default=1.0)
    prog.add_argument("--hold-max", type=float, default=3.0)
    prog.add_argument("--smooth-ms", type=float, default=25.0)
    prog.add_argument("--seed", type=int, default=42)
    prog.add_argument("--pause-free-tail-frac", type=float, default=0.25,
                      help="Fraction (0..1) of the ramp at the end where pauses are disabled (continuous approach).")

    # Stops + easing + slews + interpolation
    prog.add_argument("--stop-when-spacing-hz", type=float, default=None)
    prog.add_argument("--stop-when-first-notch-hz", type=float, default=None)
    prog.add_argument("--stop-at-peak", action="store_true", default=False)
    prog.add_argument("--ease-to-hold-ms", type=float, default=200.0)
    prog.add_argument("--delay-slew-ms", type=float, default=12.0)
    prog.add_argument("--mix-slew-ms", type=float, default=15.0)
    prog.add_argument("--feedback-slew-ms", type=float, default=25.0)
    prog.add_argument("--interp", type=str, choices=["linear", "cubic"], default="linear")

    # Linearization / shaping
    prog.add_argument("--sweep-domain", type=str, default="delay",
                      choices=["delay", "f0", "spacing", "logf0"])
    prog.add_argument("--progress-gamma", type=float, default=1.0,
                      help="Exponent for ramp progress shaping (>1 straightens the late portion).")

    # Optional extra final freeze (parity)
    prog.add_argument("--final-freeze-seconds", type=float, default=0.0)

    # ---- Crest-cap / leveler options ----
    prog.add_argument("--crest-cap-db", type=float, default=12.0,
                      help="Cap local crest factor (peak_dB - RMS_dB). Lower = stronger.")
    prog.add_argument("--crest-attack-ms", type=float, default=3.0)
    prog.add_argument("--crest-release-ms", type=float, default=80.0)
    prog.add_argument("--crest-peak-window-ms", type=float, default=10.0,
                      help="Window for sliding absolute peak.")
    prog.add_argument("--crest-rms-window-ms", type=float, default=200.0,
                      help="Window for RMS used in crest calculation.")
    prog.add_argument("--crest-hp-weight-hz", type=float, default=60.0,
                      help="High-pass for RMS weighting (0 to disable).")

    prog.add_argument("--leveler-target-db", type=float, default=None,
                      help="Short-term loudness target in dBFS (e.g., -12). None disables.")
    prog.add_argument("--leveler-window-ms", type=float, default=300.0)
    prog.add_argument("--leveler-attack-ms", type=float, default=40.0)
    prog.add_argument("--leveler-release-ms", type=float, default=200.0)
    prog.add_argument("--leveler-max-up-db", type=float, default=6.0)
    prog.add_argument("--leveler-max-down-db", type=float, default=12.0)
    prog.add_argument("--leveler-hp-weight-hz", type=float, default=60.0)

    # Post / loudness options
    prog.add_argument("--normalize-rms-db", type=float, default=None,
                      help="If set (e.g., -18), normalize RMS to this dBFS before limiting.")
    prog.add_argument("--tp-ceiling-db", type=float, default=None,
                      help="Enable true-peak limiter with this ceiling (dBTP), e.g., -1.0. None disables.")
    prog.add_argument("--limiter-lookahead-ms", type=float, default=2.0)
    prog.add_argument("--limiter-release-ms", type=float, default=60.0)
    prog.add_argument("--limiter-oversample", type=int, default=4, choices=[1, 2, 3, 4, 6, 8],
                      help="Limiter oversampling factor.")
    prog.add_argument("--softclip-drive-db", type=float, default=0.0,
                      help="Optional tanh soft-clip drive in dB (0 disables).")
    prog.add_argument("--output-subtype", type=str, default="PCM_24",
                      choices=["PCM_16", "PCM_24", "FLOAT"],
                      help="Output file subtype/bit-depth.")

    args = parser.parse_args()

    if args.mode == "flange":
        audio = generate_flanged_noise(
            duration_seconds=args.duration,
            sample_rate=DEFAULT_SAMPLE_RATE,
            noise_type=args.noise_type,
            lfo_freq=args.lfo_freq,
            max_delay_ms=args.max_delay_ms,
            mix=args.mix,
            direction=args.direction,
            lfo_waveform=args.lfo_waveform,
        )
        sf.write(args.output, audio, DEFAULT_SAMPLE_RATE, subtype="PCM_16")

    elif args.mode == "notch":
        dual_sweeps_config = [(500, 1000), (1850, 3350)]
        generate_swept_notch_pink_sound(
            filename=args.output,
            duration_seconds=args.duration,
            sample_rate=DEFAULT_SAMPLE_RATE,
            lfo_freq=args.lfo_freq,
            filter_sweeps=dual_sweeps_config,
            notch_q=40,
            cascade_count=15,
            lfo_phase_offset_deg=90,
            lfo_waveform=args.lfo_waveform,
        )

    elif args.mode == "flange-progression":
        generate_flanged_noise_progression(
            filename=args.output,
            duration_seconds=args.duration,
            sample_rate=DEFAULT_SAMPLE_RATE,
            noise_type=args.noise_type,
            # macro
            start_rate_hz=args.start_rate_hz,
            end_rate_hz=args.end_rate_hz,
            start_center_ms=args.start_center_ms,
            end_center_ms=args.end_center_ms,
            start_depth_ms=args.start_depth_ms,
            end_depth_ms=args.end_depth_ms,
            start_mix=args.start_mix,
            end_mix=args.end_mix,
            start_feedback=args.start_feedback,
            end_feedback=args.end_feedback,
            # direction/timing
            direction=args.direction,
            ramp_seconds=args.ramp_seconds,
            freeze_seconds=args.freeze_seconds,
            initial_freeze_seconds=args.initial_freeze_seconds,
            final_freeze_at_last_sec=args.final_freeze_seconds,
            # pauses
            run_range=(args.run_min, args.run_max),
            hold_range=(args.hold_min, args.hold_max),
            smooth_ms=args.smooth_ms,
            rng_seed=args.seed,
            pauses_during_ramp=args.pauses_during_ramp,
            pause_free_tail_frac=args.pause_free_tail_frac,
            # stops + shaping
            stop_when_spacing_hz=args.stop_when_spacing_hz,
            stop_when_first_notch_hz=args.stop_when_first_notch_hz,
            stop_at_peak=args.stop_at_peak,
            ease_to_hold_ms=args.ease_to_hold_ms,
            delay_slew_ms=args.delay_slew_ms,
            mix_slew_ms=args.mix_slew_ms,
            feedback_slew_ms=args.feedback_slew_ms,
            interp=args.interp,
            sweep_domain=args.sweep_domain,
            progress_gamma=args.progress_gamma,
            # crest-cap / leveler
            crest_cap_db=args.crest_cap_db,
            crest_attack_ms=args.crest_attack_ms,
            crest_release_ms=args.crest_release_ms,
            crest_peak_window_ms=args.crest_peak_window_ms,
            crest_rms_window_ms=args.crest_rms_window_ms,
            crest_hp_weight_hz=args.crest_hp_weight_hz,
            leveler_target_db=args.leveler_target_db,
            leveler_window_ms=args.leveler_window_ms,
            leveler_attack_ms=args.leveler_attack_ms,
            leveler_release_ms=args.leveler_release_ms,
            leveler_max_up_db=args.leveler_max_up_db,
            leveler_max_down_db=args.leveler_max_down_db,
            leveler_hp_weight_hz=args.leveler_hp_weight_hz,
            # post
            normalize_rms_db=args.normalize_rms_db,
            tp_ceiling_db=args.tp_ceiling_db,
            limiter_lookahead_ms=args.limiter_lookahead_ms,
            limiter_release_ms=args.limiter_release_ms,
            limiter_oversample=args.limiter_oversample,
            softclip_drive_db=args.softclip_drive_db,
            output_subtype=args.output_subtype,
        )


if __name__ == "__main__":
    main()





# ==========================================
# Synth Function Wrappers for Noise
# ==========================================

def noise_swept_notch(
    duration,
    sample_rate,
    lfo_freq=0.1,
    sweeps=None,
    notch_q=None,
    casc=None,
    start_lfo_phase_offset_deg=0.0,
    start_intra_phase_offset_deg=0.0,
    input_audio_path=None,
    noise_type="pink",
    lfo_waveform="sine",
    stereo_phase_invert=False,
    channels=2,
    static_notches=None,
    volume=1.0,
    **kwargs
):
    """
    Wrapper for _generate_swept_notch_arrays to be used as a synth function voice.
    Adapts the flat argument list to the specific arguments required by the internal generator.
    """
    # Handle input_audio_path being empty string
    if input_audio_path == "":
        input_audio_path = None

    # Parse sweeps using the helper to handle list of dicts or tuples
    # This returns (filter_sweeps, q_vals, casc_vals)
    filter_sweeps, parsed_q, parsed_casc = _prepare_static_sweeps(sweeps)
    
    num_sweeps = len(filter_sweeps)

    # Handle notch_q broadcasting/override
    if notch_q is None:
        notch_q = parsed_q
    elif isinstance(notch_q, (int, float)):
        notch_q = [float(notch_q)] * num_sweeps
    elif isinstance(notch_q, (list, tuple)):
        if len(notch_q) == 1 and num_sweeps > 1:
            notch_q = [float(notch_q[0])] * num_sweeps
        else:
            notch_q = [float(q) for q in notch_q]

    # Handle casc broadcasting/override
    if casc is None:
        casc = parsed_casc
    elif isinstance(casc, int):
        casc = [int(casc)] * num_sweeps
    elif isinstance(casc, (list, tuple)):
        if len(casc) == 1 and num_sweeps > 1:
            casc = [int(casc[0])] * num_sweeps
        else:
            casc = [int(c) for c in casc]
    
    # Generate the noise
    audio, _ = _generate_swept_notch_arrays(
        duration,
        sample_rate,
        lfo_freq,
        filter_sweeps,
        notch_q,
        casc,
        start_lfo_phase_offset_deg,
        start_intra_phase_offset_deg,
        input_audio_path,
        noise_type,
        lfo_waveform,
        stereo_phase_invert,
        channels,
        static_notches
    )
    
    # Apply volume
    if volume != 1.0:
        audio *= volume
        
    return audio


def noise_swept_notch_transition(
    duration,
    sample_rate,
    start_lfo_freq=0.1,
    end_lfo_freq=0.1,
    start_sweeps=None,
    end_sweeps=None,
    start_q=None,
    end_q=None,
    start_casc=None,
    end_casc=None,
    start_lfo_phase_offset_deg=0.0,
    end_lfo_phase_offset_deg=0.0,
    start_intra_phase_offset_deg=0.0,
    end_intra_phase_offset_deg=0.0,
    input_audio_path=None,
    noise_type="pink",
    lfo_waveform="sine",
    initial_offset=0.0,
    transition_duration=None,
    transition_curve="linear",
    stereo_phase_invert=False,
    channels=2,
    static_notches=None,
    volume=1.0,
    **kwargs
):
    """
    Wrapper for _generate_swept_notch_arrays_transition to be used as a synth function voice.
    """
    # Handle input_audio_path being empty string
    if input_audio_path == "":
        input_audio_path = None

    # Parse sweeps using the transition helper
    # This returns (start_sweeps, end_sweeps, start_q_vals, end_q_vals, start_casc, end_casc)
    # We pass 'start_sweeps' argument as the input because that's likely where the list of dicts is passed
    # if the UI sends a single 'sweeps' list, it might be in start_sweeps or kwargs.
    # But based on the error log, the param is named 'sweeps'.
    
    sweeps_input = kwargs.get('sweeps', start_sweeps)
    if sweeps_input is None:
        sweeps_input = start_sweeps

    (
        parsed_start_sweeps,
        parsed_end_sweeps,
        parsed_start_q,
        parsed_end_q,
        parsed_start_casc,
        parsed_end_casc
    ) = _prepare_transition_sweeps(sweeps_input)
    
    num_sweeps = len(parsed_start_sweeps)

    # Handle start_q broadcasting/override
    if start_q is None:
        start_q = parsed_start_q
    elif isinstance(start_q, (int, float)):
        start_q = [float(start_q)] * num_sweeps
    elif isinstance(start_q, (list, tuple)):
        if len(start_q) == 1 and num_sweeps > 1:
            start_q = [float(start_q[0])] * num_sweeps
        else:
            start_q = [float(q) for q in start_q]

    # Handle end_q broadcasting/override
    if end_q is None:
        end_q = parsed_end_q
    elif isinstance(end_q, (int, float)):
        end_q = [float(end_q)] * num_sweeps
    elif isinstance(end_q, (list, tuple)):
        if len(end_q) == 1 and num_sweeps > 1:
            end_q = [float(end_q[0])] * num_sweeps
        else:
            end_q = [float(q) for q in end_q]

    # Handle start_casc broadcasting/override
    if start_casc is None:
        start_casc = parsed_start_casc
    elif isinstance(start_casc, int):
        start_casc = [int(start_casc)] * num_sweeps
    elif isinstance(start_casc, (list, tuple)):
        if len(start_casc) == 1 and num_sweeps > 1:
            start_casc = [int(start_casc[0])] * num_sweeps
        else:
            start_casc = [int(c) for c in start_casc]

    # Handle end_casc broadcasting/override
    if end_casc is None:
        end_casc = parsed_end_casc
    elif isinstance(end_casc, int):
        end_casc = [int(end_casc)] * num_sweeps
    elif isinstance(end_casc, (list, tuple)):
        if len(end_casc) == 1 and num_sweeps > 1:
            end_casc = [int(end_casc[0])] * num_sweeps
        else:
            end_casc = [int(c) for c in end_casc]

    # Generate the noise
    audio, _ = _generate_swept_notch_arrays_transition(
        duration,
        sample_rate,
        start_lfo_freq,
        end_lfo_freq,
        parsed_start_sweeps,
        parsed_end_sweeps,
        start_q,
        end_q,
        start_casc,
        end_casc,
        start_lfo_phase_offset_deg,
        end_lfo_phase_offset_deg,
        start_intra_phase_offset_deg,
        end_intra_phase_offset_deg,
        input_audio_path,
        noise_type,
        lfo_waveform,
        initial_offset,
        transition_duration if transition_duration is not None else duration,
        transition_curve,
        stereo_phase_invert,
        channels,
        static_notches
    )

    # Apply volume
    if volume != 1.0:
        audio *= volume
        
    return audio

